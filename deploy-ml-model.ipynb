{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv(\"datasets/iris/iris.csv\")\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('Species', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenemos un problema de clasificación múltiple\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos a cambiar nuestro array con los labels a 'one-hot-encoder'\n",
    "y = encoder.fit_transform(y)\n",
    "# Mostramos los 5 primeros. Hemos convertido las especies 'setosa', 'versicolor', 'virginica'\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test split y creación de un Scaler para los datos.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creación de un Scaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora transformamos los datos de train y test\n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tengamos en cuenta que tenemos que guardar el objeto scaler para poder luego utilizarlo en procesos sucesivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora tenemos que crear la red neuronal con Keras y TensorFlow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del modelo\n",
    "model = Sequential()\n",
    "# Capa de entrada\n",
    "model.add(Dense(units=4, activation='relu', input_shape=[4, ]))\n",
    "# Capa de salida\n",
    "model.add(Dense(units=3, activation='softmax'))  # Porque tenemos una función de clasificación múltiple\n",
    "# Compilamos el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregación de un early stopping para evitar overfitting\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1356 - accuracy: 0.3250 - val_loss: 1.1171 - val_accuracy: 0.3667\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1324 - accuracy: 0.3250 - val_loss: 1.1134 - val_accuracy: 0.3667\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1297 - accuracy: 0.3250 - val_loss: 1.1098 - val_accuracy: 0.3667\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1264 - accuracy: 0.3250 - val_loss: 1.1069 - val_accuracy: 0.3667\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1236 - accuracy: 0.3250 - val_loss: 1.1041 - val_accuracy: 0.3667\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1208 - accuracy: 0.3250 - val_loss: 1.1011 - val_accuracy: 0.3667\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1181 - accuracy: 0.3250 - val_loss: 1.0982 - val_accuracy: 0.3667\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1154 - accuracy: 0.3250 - val_loss: 1.0954 - val_accuracy: 0.3667\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1128 - accuracy: 0.3250 - val_loss: 1.0926 - val_accuracy: 0.3667\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1102 - accuracy: 0.3250 - val_loss: 1.0898 - val_accuracy: 0.3667\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1074 - accuracy: 0.3250 - val_loss: 1.0870 - val_accuracy: 0.3667\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1048 - accuracy: 0.3250 - val_loss: 1.0843 - val_accuracy: 0.3667\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1021 - accuracy: 0.3250 - val_loss: 1.0816 - val_accuracy: 0.3667\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0996 - accuracy: 0.3250 - val_loss: 1.0788 - val_accuracy: 0.3667\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0970 - accuracy: 0.3250 - val_loss: 1.0760 - val_accuracy: 0.3667\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0945 - accuracy: 0.3250 - val_loss: 1.0731 - val_accuracy: 0.3667\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0918 - accuracy: 0.3250 - val_loss: 1.0703 - val_accuracy: 0.3667\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0891 - accuracy: 0.3250 - val_loss: 1.0674 - val_accuracy: 0.3667\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0862 - accuracy: 0.3250 - val_loss: 1.0644 - val_accuracy: 0.3667\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0835 - accuracy: 0.3250 - val_loss: 1.0612 - val_accuracy: 0.3667\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0803 - accuracy: 0.3250 - val_loss: 1.0579 - val_accuracy: 0.3667\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0771 - accuracy: 0.3250 - val_loss: 1.0546 - val_accuracy: 0.3667\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0737 - accuracy: 0.3250 - val_loss: 1.0513 - val_accuracy: 0.3667\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0702 - accuracy: 0.3250 - val_loss: 1.0478 - val_accuracy: 0.3667\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0666 - accuracy: 0.3250 - val_loss: 1.0440 - val_accuracy: 0.3667\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0630 - accuracy: 0.3250 - val_loss: 1.0403 - val_accuracy: 0.3667\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0590 - accuracy: 0.3333 - val_loss: 1.0366 - val_accuracy: 0.3667\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0552 - accuracy: 0.3417 - val_loss: 1.0327 - val_accuracy: 0.3667\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0515 - accuracy: 0.3500 - val_loss: 1.0288 - val_accuracy: 0.4333\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0474 - accuracy: 0.3750 - val_loss: 1.0248 - val_accuracy: 0.5000\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0435 - accuracy: 0.3917 - val_loss: 1.0208 - val_accuracy: 0.5333\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0395 - accuracy: 0.4167 - val_loss: 1.0166 - val_accuracy: 0.5333\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0353 - accuracy: 0.4333 - val_loss: 1.0124 - val_accuracy: 0.5667\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0312 - accuracy: 0.4583 - val_loss: 1.0082 - val_accuracy: 0.5667\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0269 - accuracy: 0.5000 - val_loss: 1.0040 - val_accuracy: 0.5667\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0228 - accuracy: 0.5250 - val_loss: 0.9997 - val_accuracy: 0.6000\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0184 - accuracy: 0.5667 - val_loss: 0.9954 - val_accuracy: 0.6000\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0143 - accuracy: 0.5917 - val_loss: 0.9911 - val_accuracy: 0.6667\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0099 - accuracy: 0.6167 - val_loss: 0.9868 - val_accuracy: 0.7000\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0056 - accuracy: 0.6167 - val_loss: 0.9826 - val_accuracy: 0.7000\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0016 - accuracy: 0.6250 - val_loss: 0.9783 - val_accuracy: 0.7000\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9974 - accuracy: 0.6333 - val_loss: 0.9741 - val_accuracy: 0.7000\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9934 - accuracy: 0.6417 - val_loss: 0.9700 - val_accuracy: 0.7000\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9893 - accuracy: 0.6583 - val_loss: 0.9658 - val_accuracy: 0.7000\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9850 - accuracy: 0.6583 - val_loss: 0.9617 - val_accuracy: 0.7000\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9810 - accuracy: 0.6583 - val_loss: 0.9575 - val_accuracy: 0.7000\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9767 - accuracy: 0.6583 - val_loss: 0.9533 - val_accuracy: 0.7000\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9724 - accuracy: 0.6583 - val_loss: 0.9491 - val_accuracy: 0.7000\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9683 - accuracy: 0.6583 - val_loss: 0.9448 - val_accuracy: 0.7000\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9639 - accuracy: 0.6583 - val_loss: 0.9406 - val_accuracy: 0.7000\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9597 - accuracy: 0.6583 - val_loss: 0.9363 - val_accuracy: 0.7000\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9554 - accuracy: 0.6583 - val_loss: 0.9320 - val_accuracy: 0.7000\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9511 - accuracy: 0.6583 - val_loss: 0.9277 - val_accuracy: 0.7000\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9467 - accuracy: 0.6583 - val_loss: 0.9233 - val_accuracy: 0.7000\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9426 - accuracy: 0.6583 - val_loss: 0.9190 - val_accuracy: 0.7000\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9580 - accuracy: 0.65 - 0s 3ms/step - loss: 0.9381 - accuracy: 0.6583 - val_loss: 0.9147 - val_accuracy: 0.7000\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9336 - accuracy: 0.6583 - val_loss: 0.9105 - val_accuracy: 0.7000\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9293 - accuracy: 0.6583 - val_loss: 0.9062 - val_accuracy: 0.7000\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9249 - accuracy: 0.6583 - val_loss: 0.9019 - val_accuracy: 0.7000\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9206 - accuracy: 0.6583 - val_loss: 0.8975 - val_accuracy: 0.7000\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9162 - accuracy: 0.6583 - val_loss: 0.8931 - val_accuracy: 0.7000\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9117 - accuracy: 0.6583 - val_loss: 0.8887 - val_accuracy: 0.7000\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9073 - accuracy: 0.6583 - val_loss: 0.8844 - val_accuracy: 0.7000\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9028 - accuracy: 0.6583 - val_loss: 0.8800 - val_accuracy: 0.7000\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8985 - accuracy: 0.6583 - val_loss: 0.8756 - val_accuracy: 0.7000\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8940 - accuracy: 0.6583 - val_loss: 0.8711 - val_accuracy: 0.7000\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8895 - accuracy: 0.6583 - val_loss: 0.8668 - val_accuracy: 0.7000\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8851 - accuracy: 0.6583 - val_loss: 0.8622 - val_accuracy: 0.7000\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8807 - accuracy: 0.6583 - val_loss: 0.8578 - val_accuracy: 0.7000\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8763 - accuracy: 0.6583 - val_loss: 0.8532 - val_accuracy: 0.7000\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8718 - accuracy: 0.6583 - val_loss: 0.8488 - val_accuracy: 0.7000\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8673 - accuracy: 0.6583 - val_loss: 0.8445 - val_accuracy: 0.7000\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8630 - accuracy: 0.6583 - val_loss: 0.8401 - val_accuracy: 0.7000\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8586 - accuracy: 0.6583 - val_loss: 0.8357 - val_accuracy: 0.7000\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8542 - accuracy: 0.6583 - val_loss: 0.8313 - val_accuracy: 0.7000\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8498 - accuracy: 0.6583 - val_loss: 0.8270 - val_accuracy: 0.7000\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8454 - accuracy: 0.6583 - val_loss: 0.8226 - val_accuracy: 0.7000\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8410 - accuracy: 0.6583 - val_loss: 0.8183 - val_accuracy: 0.7000\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8367 - accuracy: 0.6583 - val_loss: 0.8139 - val_accuracy: 0.7000\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8323 - accuracy: 0.6583 - val_loss: 0.8096 - val_accuracy: 0.7000\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8280 - accuracy: 0.6583 - val_loss: 0.8053 - val_accuracy: 0.7000\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8238 - accuracy: 0.6583 - val_loss: 0.8010 - val_accuracy: 0.7000\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8194 - accuracy: 0.6583 - val_loss: 0.7968 - val_accuracy: 0.7000\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8151 - accuracy: 0.6583 - val_loss: 0.7925 - val_accuracy: 0.7000\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8108 - accuracy: 0.6583 - val_loss: 0.7883 - val_accuracy: 0.7000\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8067 - accuracy: 0.6583 - val_loss: 0.7840 - val_accuracy: 0.7000\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8023 - accuracy: 0.6583 - val_loss: 0.7798 - val_accuracy: 0.7000\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7981 - accuracy: 0.6583 - val_loss: 0.7756 - val_accuracy: 0.7000\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7940 - accuracy: 0.6583 - val_loss: 0.7715 - val_accuracy: 0.7000\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7898 - accuracy: 0.6583 - val_loss: 0.7674 - val_accuracy: 0.7000\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7857 - accuracy: 0.6583 - val_loss: 0.7632 - val_accuracy: 0.7000\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7816 - accuracy: 0.6583 - val_loss: 0.7590 - val_accuracy: 0.7000\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7774 - accuracy: 0.6583 - val_loss: 0.7550 - val_accuracy: 0.7000\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7734 - accuracy: 0.6583 - val_loss: 0.7510 - val_accuracy: 0.7000\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7693 - accuracy: 0.6583 - val_loss: 0.7469 - val_accuracy: 0.7000\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7653 - accuracy: 0.6583 - val_loss: 0.7429 - val_accuracy: 0.7000\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7612 - accuracy: 0.6583 - val_loss: 0.7389 - val_accuracy: 0.7000\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7572 - accuracy: 0.6583 - val_loss: 0.7350 - val_accuracy: 0.7000\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7534 - accuracy: 0.6583 - val_loss: 0.7310 - val_accuracy: 0.7000\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7495 - accuracy: 0.6583 - val_loss: 0.7271 - val_accuracy: 0.7000\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7455 - accuracy: 0.6583 - val_loss: 0.7233 - val_accuracy: 0.7000\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.6583 - val_loss: 0.7195 - val_accuracy: 0.7000\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7379 - accuracy: 0.6583 - val_loss: 0.7157 - val_accuracy: 0.7000\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7342 - accuracy: 0.6583 - val_loss: 0.7120 - val_accuracy: 0.7000\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7304 - accuracy: 0.6583 - val_loss: 0.7084 - val_accuracy: 0.7000\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7267 - accuracy: 0.6583 - val_loss: 0.7047 - val_accuracy: 0.7000\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7230 - accuracy: 0.6583 - val_loss: 0.7010 - val_accuracy: 0.7000\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7193 - accuracy: 0.6583 - val_loss: 0.6974 - val_accuracy: 0.7000\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7157 - accuracy: 0.6583 - val_loss: 0.6937 - val_accuracy: 0.7000\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7121 - accuracy: 0.6583 - val_loss: 0.6902 - val_accuracy: 0.7000\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7086 - accuracy: 0.6583 - val_loss: 0.6866 - val_accuracy: 0.7000\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7050 - accuracy: 0.6583 - val_loss: 0.6831 - val_accuracy: 0.7000\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7016 - accuracy: 0.6583 - val_loss: 0.6796 - val_accuracy: 0.7000\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6980 - accuracy: 0.6583 - val_loss: 0.6762 - val_accuracy: 0.7000\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.6583 - val_loss: 0.6729 - val_accuracy: 0.7000\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6912 - accuracy: 0.6583 - val_loss: 0.6695 - val_accuracy: 0.7000\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.6583 - val_loss: 0.6662 - val_accuracy: 0.7000\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6846 - accuracy: 0.6583 - val_loss: 0.6629 - val_accuracy: 0.7000\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.6583 - val_loss: 0.6597 - val_accuracy: 0.7000\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6780 - accuracy: 0.6583 - val_loss: 0.6564 - val_accuracy: 0.7000\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 0.6667 - val_loss: 0.6533 - val_accuracy: 0.7000\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.6667 - val_loss: 0.6501 - val_accuracy: 0.7000\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.6667 - val_loss: 0.6470 - val_accuracy: 0.7000\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.6667 - val_loss: 0.6439 - val_accuracy: 0.7000\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.6667 - val_loss: 0.6409 - val_accuracy: 0.7000\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.6667 - val_loss: 0.6378 - val_accuracy: 0.7000\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.6667 - val_loss: 0.6348 - val_accuracy: 0.7000\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6531 - accuracy: 0.6667 - val_loss: 0.6318 - val_accuracy: 0.7000\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6501 - accuracy: 0.6667 - val_loss: 0.6289 - val_accuracy: 0.7000\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.6667 - val_loss: 0.6259 - val_accuracy: 0.7000\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.6750 - val_loss: 0.6231 - val_accuracy: 0.7000\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.6750 - val_loss: 0.6202 - val_accuracy: 0.7000\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.6750 - val_loss: 0.6174 - val_accuracy: 0.7000\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.6750 - val_loss: 0.6146 - val_accuracy: 0.7000\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.6750 - val_loss: 0.6118 - val_accuracy: 0.7000\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.6750 - val_loss: 0.6091 - val_accuracy: 0.7000\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.6750 - val_loss: 0.6065 - val_accuracy: 0.7000\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.6750 - val_loss: 0.6040 - val_accuracy: 0.7000\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6224 - accuracy: 0.6750 - val_loss: 0.6013 - val_accuracy: 0.7000\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.6750 - val_loss: 0.5988 - val_accuracy: 0.7000\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.6750 - val_loss: 0.5964 - val_accuracy: 0.7000\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.6833 - val_loss: 0.5939 - val_accuracy: 0.7000\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.6833 - val_loss: 0.5914 - val_accuracy: 0.7000\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.6833 - val_loss: 0.5890 - val_accuracy: 0.7000\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6072 - accuracy: 0.6917 - val_loss: 0.5866 - val_accuracy: 0.7000\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.6917 - val_loss: 0.5842 - val_accuracy: 0.7000\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6024 - accuracy: 0.6917 - val_loss: 0.5819 - val_accuracy: 0.7000\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.6917 - val_loss: 0.5795 - val_accuracy: 0.7000\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5977 - accuracy: 0.6917 - val_loss: 0.5773 - val_accuracy: 0.7000\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.6917 - val_loss: 0.5750 - val_accuracy: 0.7000\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.6917 - val_loss: 0.5728 - val_accuracy: 0.7000\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.6917 - val_loss: 0.5705 - val_accuracy: 0.7000\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.6917 - val_loss: 0.5683 - val_accuracy: 0.7000\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.6917 - val_loss: 0.5662 - val_accuracy: 0.7000\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.6917 - val_loss: 0.5641 - val_accuracy: 0.7000\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7000 - val_loss: 0.5620 - val_accuracy: 0.7000\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.7000 - val_loss: 0.5599 - val_accuracy: 0.7000\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.7083 - val_loss: 0.5578 - val_accuracy: 0.7000\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.7083 - val_loss: 0.5556 - val_accuracy: 0.7000\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.7167 - val_loss: 0.5537 - val_accuracy: 0.7000\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.7167 - val_loss: 0.5516 - val_accuracy: 0.7000\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.7167 - val_loss: 0.5496 - val_accuracy: 0.7000\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.7167 - val_loss: 0.5476 - val_accuracy: 0.7000\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.7167 - val_loss: 0.5457 - val_accuracy: 0.7000\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.7167 - val_loss: 0.5439 - val_accuracy: 0.7000\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7167 - val_loss: 0.5420 - val_accuracy: 0.7000\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.7167 - val_loss: 0.5402 - val_accuracy: 0.7000\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7167 - val_loss: 0.5384 - val_accuracy: 0.7000\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7167 - val_loss: 0.5366 - val_accuracy: 0.7000\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.7250 - val_loss: 0.5348 - val_accuracy: 0.7000\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.7250 - val_loss: 0.5330 - val_accuracy: 0.7000\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7250 - val_loss: 0.5311 - val_accuracy: 0.7000\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7250 - val_loss: 0.5294 - val_accuracy: 0.7000\n",
      "Epoch 174/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7250 - val_loss: 0.5278 - val_accuracy: 0.7000\n",
      "Epoch 175/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7333 - val_loss: 0.5261 - val_accuracy: 0.7000\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.7333 - val_loss: 0.5244 - val_accuracy: 0.7333\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7333 - val_loss: 0.5228 - val_accuracy: 0.7333\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7333 - val_loss: 0.5212 - val_accuracy: 0.7333\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7333 - val_loss: 0.5196 - val_accuracy: 0.7333\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7333 - val_loss: 0.5181 - val_accuracy: 0.7333\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7417 - val_loss: 0.5165 - val_accuracy: 0.7333\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7500 - val_loss: 0.5149 - val_accuracy: 0.7333\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7500 - val_loss: 0.5133 - val_accuracy: 0.7333\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7500 - val_loss: 0.5118 - val_accuracy: 0.7333\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.7500 - val_loss: 0.5103 - val_accuracy: 0.7333\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.7500 - val_loss: 0.5088 - val_accuracy: 0.7333\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7500 - val_loss: 0.5074 - val_accuracy: 0.7333\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7500 - val_loss: 0.5059 - val_accuracy: 0.7333\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7500 - val_loss: 0.5044 - val_accuracy: 0.7333\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7500 - val_loss: 0.5030 - val_accuracy: 0.7333\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7500 - val_loss: 0.5016 - val_accuracy: 0.7333\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7500 - val_loss: 0.5002 - val_accuracy: 0.7333\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7500 - val_loss: 0.4989 - val_accuracy: 0.7333\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7583 - val_loss: 0.4975 - val_accuracy: 0.7667\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7583 - val_loss: 0.4962 - val_accuracy: 0.7667\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7583 - val_loss: 0.4949 - val_accuracy: 0.7667\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7583 - val_loss: 0.4937 - val_accuracy: 0.7667\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7583 - val_loss: 0.4925 - val_accuracy: 0.7667\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7583 - val_loss: 0.4913 - val_accuracy: 0.7667\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7667 - val_loss: 0.4901 - val_accuracy: 0.7667\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7667 - val_loss: 0.4888 - val_accuracy: 0.7667\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7667 - val_loss: 0.4875 - val_accuracy: 0.7667\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7667 - val_loss: 0.4863 - val_accuracy: 0.7667\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7667 - val_loss: 0.4851 - val_accuracy: 0.8000\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7667 - val_loss: 0.4839 - val_accuracy: 0.8000\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7667 - val_loss: 0.4828 - val_accuracy: 0.8000\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7667 - val_loss: 0.4817 - val_accuracy: 0.8000\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7750 - val_loss: 0.4805 - val_accuracy: 0.8000\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.7833 - val_loss: 0.4794 - val_accuracy: 0.8000\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.7833 - val_loss: 0.4783 - val_accuracy: 0.8000\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7833 - val_loss: 0.4771 - val_accuracy: 0.8000\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7833 - val_loss: 0.4760 - val_accuracy: 0.8000\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.7833 - val_loss: 0.4750 - val_accuracy: 0.8333\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.8000 - val_loss: 0.4739 - val_accuracy: 0.8333\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.8000 - val_loss: 0.4728 - val_accuracy: 0.8333\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.8083 - val_loss: 0.4717 - val_accuracy: 0.8333\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.8083 - val_loss: 0.4707 - val_accuracy: 0.8333\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.8083 - val_loss: 0.4697 - val_accuracy: 0.8333\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.8083 - val_loss: 0.4687 - val_accuracy: 0.8333\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.8083 - val_loss: 0.4676 - val_accuracy: 0.8333\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.8083 - val_loss: 0.4666 - val_accuracy: 0.8333\n",
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.8083 - val_loss: 0.4655 - val_accuracy: 0.8333\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.8083 - val_loss: 0.4645 - val_accuracy: 0.8333\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.8083 - val_loss: 0.4635 - val_accuracy: 0.8333\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.8083 - val_loss: 0.4625 - val_accuracy: 0.8333\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.8167 - val_loss: 0.4616 - val_accuracy: 0.8333\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.8167 - val_loss: 0.4607 - val_accuracy: 0.8333\n",
      "Epoch 228/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.8167 - val_loss: 0.4597 - val_accuracy: 0.8333\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.8167 - val_loss: 0.4588 - val_accuracy: 0.8333\n",
      "Epoch 230/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.8167 - val_loss: 0.4580 - val_accuracy: 0.8333\n",
      "Epoch 231/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.8167 - val_loss: 0.4570 - val_accuracy: 0.8333\n",
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.8167 - val_loss: 0.4560 - val_accuracy: 0.8333\n",
      "Epoch 233/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.8167 - val_loss: 0.4551 - val_accuracy: 0.8333\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.8167 - val_loss: 0.4541 - val_accuracy: 0.8333\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.8167 - val_loss: 0.4532 - val_accuracy: 0.8333\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.8167 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.8167 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.8167 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 239/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.8167 - val_loss: 0.4497 - val_accuracy: 0.8333\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.8167 - val_loss: 0.4489 - val_accuracy: 0.8333\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.8167 - val_loss: 0.4481 - val_accuracy: 0.8333\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.8167 - val_loss: 0.4473 - val_accuracy: 0.8667\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.8333 - val_loss: 0.4464 - val_accuracy: 0.8667\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.8333 - val_loss: 0.4456 - val_accuracy: 0.8667\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.8333 - val_loss: 0.4448 - val_accuracy: 0.8667\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.8333 - val_loss: 0.4440 - val_accuracy: 0.8667\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.8333 - val_loss: 0.4432 - val_accuracy: 0.8667\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.8333 - val_loss: 0.4423 - val_accuracy: 0.8667\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.8333 - val_loss: 0.4415 - val_accuracy: 0.8667\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.8333 - val_loss: 0.4407 - val_accuracy: 0.8667\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.8333 - val_loss: 0.4399 - val_accuracy: 0.8667\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.8333 - val_loss: 0.4391 - val_accuracy: 0.8667\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.8333 - val_loss: 0.4383 - val_accuracy: 0.8667\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.8333 - val_loss: 0.4375 - val_accuracy: 0.8667\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.8333 - val_loss: 0.4368 - val_accuracy: 0.8667\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.8333 - val_loss: 0.4360 - val_accuracy: 0.8667\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.8333 - val_loss: 0.4353 - val_accuracy: 0.8667\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.8333 - val_loss: 0.4346 - val_accuracy: 0.8667\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.8333 - val_loss: 0.4339 - val_accuracy: 0.8667\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.8333 - val_loss: 0.4331 - val_accuracy: 0.8667\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.8333 - val_loss: 0.4323 - val_accuracy: 0.8667\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.8333 - val_loss: 0.4317 - val_accuracy: 0.8667\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.8333 - val_loss: 0.4310 - val_accuracy: 0.8667\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.8333 - val_loss: 0.4302 - val_accuracy: 0.8667\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.8333 - val_loss: 0.4295 - val_accuracy: 0.8667\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.8333 - val_loss: 0.4287 - val_accuracy: 0.8667\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.8333 - val_loss: 0.4279 - val_accuracy: 0.8667\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.8333 - val_loss: 0.4274 - val_accuracy: 0.8667\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.8333 - val_loss: 0.4267 - val_accuracy: 0.8667\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.8333 - val_loss: 0.4261 - val_accuracy: 0.8667\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.8333 - val_loss: 0.4254 - val_accuracy: 0.8667\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.8333 - val_loss: 0.4247 - val_accuracy: 0.8667\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.8417 - val_loss: 0.4240 - val_accuracy: 0.8667\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.8417 - val_loss: 0.4233 - val_accuracy: 0.8667\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.8417 - val_loss: 0.4227 - val_accuracy: 0.8667\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.8417 - val_loss: 0.4220 - val_accuracy: 0.8667\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.8417 - val_loss: 0.4214 - val_accuracy: 0.8667\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.8417 - val_loss: 0.4207 - val_accuracy: 0.8667\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.8417 - val_loss: 0.4201 - val_accuracy: 0.8667\n",
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.8417 - val_loss: 0.4194 - val_accuracy: 0.8667\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.8417 - val_loss: 0.4187 - val_accuracy: 0.8667\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.8417 - val_loss: 0.4180 - val_accuracy: 0.8667\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.8417 - val_loss: 0.4174 - val_accuracy: 0.8667\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5084 - accuracy: 0.81 - 0s 3ms/step - loss: 0.4388 - accuracy: 0.8417 - val_loss: 0.4168 - val_accuracy: 0.8667\n",
      "Epoch 285/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.8417 - val_loss: 0.4162 - val_accuracy: 0.8667\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.8417 - val_loss: 0.4156 - val_accuracy: 0.8667\n",
      "Epoch 287/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.8500 - val_loss: 0.4150 - val_accuracy: 0.8667\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.8417 - val_loss: 0.4143 - val_accuracy: 0.8667\n",
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.8417 - val_loss: 0.4137 - val_accuracy: 0.8667\n",
      "Epoch 290/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.8500 - val_loss: 0.4131 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.8500 - val_loss: 0.4126 - val_accuracy: 0.8667\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.8500 - val_loss: 0.4120 - val_accuracy: 0.8667\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.8500 - val_loss: 0.4114 - val_accuracy: 0.8667\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.8417 - val_loss: 0.4108 - val_accuracy: 0.8667\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.8417 - val_loss: 0.4102 - val_accuracy: 0.8667\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.8417 - val_loss: 0.4096 - val_accuracy: 0.8667\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.8417 - val_loss: 0.4091 - val_accuracy: 0.8667\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.8417 - val_loss: 0.4086 - val_accuracy: 0.8667\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8500 - val_loss: 0.4080 - val_accuracy: 0.8667\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8500 - val_loss: 0.4075 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2e94724970>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento del modelo\n",
    "model.fit(x=scaled_X_train, y=y_train, epochs=300,\n",
    "         validation_data=(scaled_X_test, y_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.135561</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.132389</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>1.113400</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.129674</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>1.109834</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.126381</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>1.106911</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.123575</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>1.104068</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.431935</td>\n",
       "      <td>0.841667</td>\n",
       "      <td>0.409609</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.431351</td>\n",
       "      <td>0.841667</td>\n",
       "      <td>0.409065</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.430840</td>\n",
       "      <td>0.841667</td>\n",
       "      <td>0.408571</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.430276</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.408026</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.429744</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.407486</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    1.135561  0.325000  1.117146      0.366667\n",
       "1    1.132389  0.325000  1.113400      0.366667\n",
       "2    1.129674  0.325000  1.109834      0.366667\n",
       "3    1.126381  0.325000  1.106911      0.366667\n",
       "4    1.123575  0.325000  1.104068      0.366667\n",
       "..        ...       ...       ...           ...\n",
       "295  0.431935  0.841667  0.409609      0.866667\n",
       "296  0.431351  0.841667  0.409065      0.866667\n",
       "297  0.430840  0.841667  0.408571      0.866667\n",
       "298  0.430276  0.850000  0.408026      0.866667\n",
       "299  0.429744  0.850000  0.407486      0.866667\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estudiemos las métricas\n",
    "metrics = pd.DataFrame(model.history.history)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2e945f3850>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dibujemos en un gráfico las funciones loss y val_loss\n",
    "metrics[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2e94501d60>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dibujemos en un gráfico las funciones accuracy y val_accuracy\n",
    "metrics[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.40748628973960876, 0.8666666746139526]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluación del modelo\n",
    "model.evaluate(scaled_X_test, y_test, verbose=0) # Lo que obtendremos es el final_loss y el final_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí es el punto en el que tenemos que decidir si estas métricas son lo suficientemente buenas\n",
    "# Hemos obtenido el 80% de precisión. ¿Es suficiente? -> Sí, entonces ...\n",
    "# Preparemos nuestro modelo para el deployment.\n",
    "# Lo que quiero es conseguir el mejor modelo posible. Para ello, utilizo ahora todos los datos.\n",
    "# Voy a aplicar nuestro Scaler a todos los datos\n",
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos ahora un nuevo modelo usando todos los datos\n",
    "model = Sequential()\n",
    "model.add(Dense(units=4, activation='relu', input_shape=[4, ]))\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 0s 532us/step - loss: 0.9293 - accuracy: 0.3333\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 631us/step - loss: 0.9236 - accuracy: 0.3333\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 580us/step - loss: 0.9188 - accuracy: 0.3333\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 700us/step - loss: 0.9138 - accuracy: 0.3333\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 627us/step - loss: 0.9089 - accuracy: 0.3333\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 596us/step - loss: 0.9039 - accuracy: 0.3333\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 695us/step - loss: 0.8992 - accuracy: 0.3333\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 606us/step - loss: 0.8944 - accuracy: 0.3333\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 561us/step - loss: 0.8897 - accuracy: 0.3333\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 627us/step - loss: 0.8853 - accuracy: 0.3333\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 578us/step - loss: 0.8806 - accuracy: 0.3333\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 787us/step - loss: 0.8763 - accuracy: 0.3333\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 751us/step - loss: 0.8719 - accuracy: 0.3400\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 676us/step - loss: 0.8673 - accuracy: 0.3533\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 658us/step - loss: 0.8630 - accuracy: 0.3667\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 706us/step - loss: 0.8587 - accuracy: 0.3933\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 565us/step - loss: 0.8545 - accuracy: 0.4067\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 569us/step - loss: 0.8503 - accuracy: 0.4333\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 893us/step - loss: 0.8464 - accuracy: 0.4667\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 672us/step - loss: 0.8423 - accuracy: 0.4867\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 639us/step - loss: 0.8382 - accuracy: 0.5133\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 683us/step - loss: 0.8342 - accuracy: 0.5400\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 633us/step - loss: 0.8301 - accuracy: 0.5467\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 674us/step - loss: 0.8262 - accuracy: 0.5667\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 697us/step - loss: 0.8221 - accuracy: 0.5867\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 582us/step - loss: 0.8185 - accuracy: 0.5867\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 587us/step - loss: 0.8145 - accuracy: 0.5933\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 672us/step - loss: 0.8104 - accuracy: 0.6067\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 561us/step - loss: 0.8068 - accuracy: 0.6133\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 571us/step - loss: 0.8031 - accuracy: 0.6200\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 666us/step - loss: 0.7992 - accuracy: 0.6200\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 725us/step - loss: 0.7956 - accuracy: 0.6267\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 501us/step - loss: 0.7920 - accuracy: 0.6267\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 622us/step - loss: 0.7882 - accuracy: 0.6467\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 582us/step - loss: 0.7845 - accuracy: 0.6533\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 623us/step - loss: 0.7811 - accuracy: 0.6533\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 740us/step - loss: 0.7773 - accuracy: 0.6533\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 585us/step - loss: 0.7738 - accuracy: 0.6667\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.7703 - accuracy: 0.6667\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 533us/step - loss: 0.7667 - accuracy: 0.6667\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 661us/step - loss: 0.7631 - accuracy: 0.6667\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 611us/step - loss: 0.7594 - accuracy: 0.6667\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 749us/step - loss: 0.7559 - accuracy: 0.6667\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 566us/step - loss: 0.7523 - accuracy: 0.6667\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 630us/step - loss: 0.7488 - accuracy: 0.6667\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 617us/step - loss: 0.7453 - accuracy: 0.6667\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 629us/step - loss: 0.7417 - accuracy: 0.6667\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 629us/step - loss: 0.7380 - accuracy: 0.6667\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 582us/step - loss: 0.7344 - accuracy: 0.6667\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 680us/step - loss: 0.7310 - accuracy: 0.6667\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 557us/step - loss: 0.7273 - accuracy: 0.6667\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 630us/step - loss: 0.7238 - accuracy: 0.6667\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 718us/step - loss: 0.7204 - accuracy: 0.6667\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 688us/step - loss: 0.7167 - accuracy: 0.6667\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 585us/step - loss: 0.7132 - accuracy: 0.6733\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 682us/step - loss: 0.7097 - accuracy: 0.6733\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 703us/step - loss: 0.7062 - accuracy: 0.6733\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 596us/step - loss: 0.7026 - accuracy: 0.6733\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 611us/step - loss: 0.6991 - accuracy: 0.6733\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 621us/step - loss: 0.6958 - accuracy: 0.6800\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 644us/step - loss: 0.6922 - accuracy: 0.6867\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 717us/step - loss: 0.6887 - accuracy: 0.6867\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.6853 - accuracy: 0.6867\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 574us/step - loss: 0.6818 - accuracy: 0.6867\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 751us/step - loss: 0.6787 - accuracy: 0.6867\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 666us/step - loss: 0.6752 - accuracy: 0.7000\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 537us/step - loss: 0.6717 - accuracy: 0.7000\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 703us/step - loss: 0.6684 - accuracy: 0.7000\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 646us/step - loss: 0.6651 - accuracy: 0.7000\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 574us/step - loss: 0.6617 - accuracy: 0.7000\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 624us/step - loss: 0.6584 - accuracy: 0.7067\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 617us/step - loss: 0.6551 - accuracy: 0.7067\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 626us/step - loss: 0.6518 - accuracy: 0.7133\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 711us/step - loss: 0.6486 - accuracy: 0.7133\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 570us/step - loss: 0.6452 - accuracy: 0.7200\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 536us/step - loss: 0.6420 - accuracy: 0.7200\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 608us/step - loss: 0.6387 - accuracy: 0.7200\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 640us/step - loss: 0.6357 - accuracy: 0.7200\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 561us/step - loss: 0.6325 - accuracy: 0.7200\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 572us/step - loss: 0.6294 - accuracy: 0.7200\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 698us/step - loss: 0.6261 - accuracy: 0.7200\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 633us/step - loss: 0.6230 - accuracy: 0.7200\n",
      "Epoch 83/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 577us/step - loss: 0.6201 - accuracy: 0.7200\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 640us/step - loss: 0.6169 - accuracy: 0.7200\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 619us/step - loss: 0.6138 - accuracy: 0.7200\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 561us/step - loss: 0.6109 - accuracy: 0.7200\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 809us/step - loss: 0.6080 - accuracy: 0.7267\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 596us/step - loss: 0.6050 - accuracy: 0.7267\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 608us/step - loss: 0.6020 - accuracy: 0.7267\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 720us/step - loss: 0.5991 - accuracy: 0.7267\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 569us/step - loss: 0.5962 - accuracy: 0.7267\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 587us/step - loss: 0.5932 - accuracy: 0.7267\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 726us/step - loss: 0.5903 - accuracy: 0.7267\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 589us/step - loss: 0.5875 - accuracy: 0.7267\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 709us/step - loss: 0.5847 - accuracy: 0.7267\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 706us/step - loss: 0.5818 - accuracy: 0.7333\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 633us/step - loss: 0.5791 - accuracy: 0.7400\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 549us/step - loss: 0.5763 - accuracy: 0.7400\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 536us/step - loss: 0.5736 - accuracy: 0.7400\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 592us/step - loss: 0.5709 - accuracy: 0.7400\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 618us/step - loss: 0.5684 - accuracy: 0.7533\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 576us/step - loss: 0.5655 - accuracy: 0.7533\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 763us/step - loss: 0.5629 - accuracy: 0.7533\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 618us/step - loss: 0.5604 - accuracy: 0.7533\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 626us/step - loss: 0.5577 - accuracy: 0.7533\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.5552 - accuracy: 0.7667\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 628us/step - loss: 0.5527 - accuracy: 0.7667\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.5501 - accuracy: 0.7733\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 766us/step - loss: 0.5477 - accuracy: 0.7733\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 659us/step - loss: 0.5451 - accuracy: 0.7733\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 623us/step - loss: 0.5428 - accuracy: 0.7733\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 695us/step - loss: 0.5403 - accuracy: 0.7733\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 695us/step - loss: 0.5379 - accuracy: 0.7800\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 545us/step - loss: 0.5356 - accuracy: 0.8000\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 541us/step - loss: 0.5332 - accuracy: 0.7933\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 582us/step - loss: 0.5308 - accuracy: 0.7933\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 516us/step - loss: 0.5286 - accuracy: 0.7933\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 627us/step - loss: 0.5263 - accuracy: 0.7933\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 641us/step - loss: 0.5242 - accuracy: 0.7933\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.5219 - accuracy: 0.7933\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 620us/step - loss: 0.5196 - accuracy: 0.8000\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 621us/step - loss: 0.5174 - accuracy: 0.8000\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 523us/step - loss: 0.5153 - accuracy: 0.8000\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 509us/step - loss: 0.5131 - accuracy: 0.8000\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 571us/step - loss: 0.5110 - accuracy: 0.8000\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 627us/step - loss: 0.5089 - accuracy: 0.8000\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 650us/step - loss: 0.5068 - accuracy: 0.8000\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 640us/step - loss: 0.5047 - accuracy: 0.8000\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 640us/step - loss: 0.5027 - accuracy: 0.8000\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 561us/step - loss: 0.5007 - accuracy: 0.8067\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 631us/step - loss: 0.4987 - accuracy: 0.8200\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 736us/step - loss: 0.4970 - accuracy: 0.8400\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 551us/step - loss: 0.4947 - accuracy: 0.8533\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 551us/step - loss: 0.4929 - accuracy: 0.8467\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 572us/step - loss: 0.4910 - accuracy: 0.8533\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 552us/step - loss: 0.4889 - accuracy: 0.8600\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 578us/step - loss: 0.4871 - accuracy: 0.8600\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 550us/step - loss: 0.4852 - accuracy: 0.8733\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 635us/step - loss: 0.4834 - accuracy: 0.8733\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 495us/step - loss: 0.4815 - accuracy: 0.8733\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 513us/step - loss: 0.4797 - accuracy: 0.8733\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 609us/step - loss: 0.4780 - accuracy: 0.8733\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 567us/step - loss: 0.4761 - accuracy: 0.8733\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 526us/step - loss: 0.4743 - accuracy: 0.8733\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 616us/step - loss: 0.4725 - accuracy: 0.8800\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 506us/step - loss: 0.4708 - accuracy: 0.8933\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 609us/step - loss: 0.4691 - accuracy: 0.9067\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 572us/step - loss: 0.4673 - accuracy: 0.9067\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.4656 - accuracy: 0.9067\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 630us/step - loss: 0.4641 - accuracy: 0.9067\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 583us/step - loss: 0.4623 - accuracy: 0.9067\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 741us/step - loss: 0.4608 - accuracy: 0.9067\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 699us/step - loss: 0.4590 - accuracy: 0.9067\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 688us/step - loss: 0.4574 - accuracy: 0.9133\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 633us/step - loss: 0.4557 - accuracy: 0.9133\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 538us/step - loss: 0.4542 - accuracy: 0.9133\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 543us/step - loss: 0.4527 - accuracy: 0.9133\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 511us/step - loss: 0.4509 - accuracy: 0.9133\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 566us/step - loss: 0.4495 - accuracy: 0.9133\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 565us/step - loss: 0.4479 - accuracy: 0.9133\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 622us/step - loss: 0.4465 - accuracy: 0.9133\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 671us/step - loss: 0.4449 - accuracy: 0.9133\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 545us/step - loss: 0.4432 - accuracy: 0.9133\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 694us/step - loss: 0.4417 - accuracy: 0.9133\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 767us/step - loss: 0.4403 - accuracy: 0.9133\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.4389 - accuracy: 0.9133\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 653us/step - loss: 0.4373 - accuracy: 0.9200\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 673us/step - loss: 0.4358 - accuracy: 0.9200\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 585us/step - loss: 0.4344 - accuracy: 0.9200\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 648us/step - loss: 0.4330 - accuracy: 0.9200\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 668us/step - loss: 0.4316 - accuracy: 0.9200\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 657us/step - loss: 0.4302 - accuracy: 0.9200\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 535us/step - loss: 0.4287 - accuracy: 0.9200\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 575us/step - loss: 0.4273 - accuracy: 0.9200\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 558us/step - loss: 0.4260 - accuracy: 0.9200\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 577us/step - loss: 0.4246 - accuracy: 0.9267\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 602us/step - loss: 0.4232 - accuracy: 0.9267\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.4220 - accuracy: 0.9267\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 585us/step - loss: 0.4205 - accuracy: 0.9267\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 636us/step - loss: 0.4194 - accuracy: 0.9400\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 630us/step - loss: 0.4179 - accuracy: 0.9400\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 579us/step - loss: 0.4166 - accuracy: 0.9400\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 622us/step - loss: 0.4153 - accuracy: 0.9400\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 611us/step - loss: 0.4141 - accuracy: 0.9400\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 552us/step - loss: 0.4128 - accuracy: 0.9400\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 584us/step - loss: 0.4114 - accuracy: 0.9400\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 640us/step - loss: 0.4101 - accuracy: 0.9400\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 621us/step - loss: 0.4088 - accuracy: 0.9400\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 648us/step - loss: 0.4075 - accuracy: 0.9400\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 506us/step - loss: 0.4063 - accuracy: 0.9400\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 571us/step - loss: 0.4051 - accuracy: 0.9400\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 634us/step - loss: 0.4039 - accuracy: 0.9400\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 577us/step - loss: 0.4025 - accuracy: 0.9400\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 635us/step - loss: 0.4013 - accuracy: 0.9400\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 554us/step - loss: 0.4003 - accuracy: 0.9400\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 587us/step - loss: 0.3991 - accuracy: 0.9400\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 757us/step - loss: 0.3977 - accuracy: 0.9400\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 577us/step - loss: 0.3968 - accuracy: 0.9400\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 590us/step - loss: 0.3953 - accuracy: 0.9400\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 622us/step - loss: 0.3942 - accuracy: 0.9400\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 794us/step - loss: 0.3930 - accuracy: 0.9400\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.3918 - accuracy: 0.9400\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 700us/step - loss: 0.3907 - accuracy: 0.9400\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 582us/step - loss: 0.3895 - accuracy: 0.9400\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 561us/step - loss: 0.3883 - accuracy: 0.9400\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 666us/step - loss: 0.3872 - accuracy: 0.9400\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 793us/step - loss: 0.3863 - accuracy: 0.9400\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 594us/step - loss: 0.3850 - accuracy: 0.9400\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 558us/step - loss: 0.3839 - accuracy: 0.9400\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 721us/step - loss: 0.3827 - accuracy: 0.9400\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 618us/step - loss: 0.3815 - accuracy: 0.9400\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 576us/step - loss: 0.3805 - accuracy: 0.9400\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 753us/step - loss: 0.3793 - accuracy: 0.9400\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 561us/step - loss: 0.3782 - accuracy: 0.9400\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 534us/step - loss: 0.3772 - accuracy: 0.9467\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 653us/step - loss: 0.3761 - accuracy: 0.9467\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 572us/step - loss: 0.3752 - accuracy: 0.9467\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 549us/step - loss: 0.3739 - accuracy: 0.9467\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 628us/step - loss: 0.3728 - accuracy: 0.9467\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 675us/step - loss: 0.3718 - accuracy: 0.9400\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 568us/step - loss: 0.3707 - accuracy: 0.9400\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 576us/step - loss: 0.3698 - accuracy: 0.9400\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 637us/step - loss: 0.3686 - accuracy: 0.9400\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 559us/step - loss: 0.3675 - accuracy: 0.9400\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 540us/step - loss: 0.3665 - accuracy: 0.9400\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 524us/step - loss: 0.3654 - accuracy: 0.9400\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 634us/step - loss: 0.3644 - accuracy: 0.9467\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 579us/step - loss: 0.3635 - accuracy: 0.9467\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 538us/step - loss: 0.3625 - accuracy: 0.9467\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 704us/step - loss: 0.3614 - accuracy: 0.9467\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 575us/step - loss: 0.3604 - accuracy: 0.9467\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 563us/step - loss: 0.3594 - accuracy: 0.9467\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 702us/step - loss: 0.3584 - accuracy: 0.9467\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 545us/step - loss: 0.3574 - accuracy: 0.9467\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 554us/step - loss: 0.3564 - accuracy: 0.9467\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 627us/step - loss: 0.3554 - accuracy: 0.9467\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 581us/step - loss: 0.3544 - accuracy: 0.9467\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 540us/step - loss: 0.3535 - accuracy: 0.9467\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 607us/step - loss: 0.3524 - accuracy: 0.9467\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 746us/step - loss: 0.3514 - accuracy: 0.9467\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 506us/step - loss: 0.3505 - accuracy: 0.9467\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 658us/step - loss: 0.3495 - accuracy: 0.9467\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 672us/step - loss: 0.3485 - accuracy: 0.9467\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 570us/step - loss: 0.3476 - accuracy: 0.9467\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 658us/step - loss: 0.3468 - accuracy: 0.9467\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 694us/step - loss: 0.3457 - accuracy: 0.9467\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 572us/step - loss: 0.3447 - accuracy: 0.9467\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 543us/step - loss: 0.3440 - accuracy: 0.9467\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 607us/step - loss: 0.3429 - accuracy: 0.9467\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 615us/step - loss: 0.3419 - accuracy: 0.9467\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 619us/step - loss: 0.3409 - accuracy: 0.9533\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 595us/step - loss: 0.3402 - accuracy: 0.9467\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 644us/step - loss: 0.3390 - accuracy: 0.9467\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 641us/step - loss: 0.3381 - accuracy: 0.9467\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 554us/step - loss: 0.3372 - accuracy: 0.9467\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 626us/step - loss: 0.3362 - accuracy: 0.9467\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 558us/step - loss: 0.3353 - accuracy: 0.9467\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 536us/step - loss: 0.3344 - accuracy: 0.9467\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 568us/step - loss: 0.3334 - accuracy: 0.9467\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 595us/step - loss: 0.3326 - accuracy: 0.9467\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 611us/step - loss: 0.3318 - accuracy: 0.9467\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 643us/step - loss: 0.3308 - accuracy: 0.9467\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 696us/step - loss: 0.3298 - accuracy: 0.9467\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 670us/step - loss: 0.3289 - accuracy: 0.9467\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 636us/step - loss: 0.3280 - accuracy: 0.9467\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 650us/step - loss: 0.3271 - accuracy: 0.9467\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 589us/step - loss: 0.3262 - accuracy: 0.9467\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 560us/step - loss: 0.3253 - accuracy: 0.9467\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 650us/step - loss: 0.3244 - accuracy: 0.9467\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 572us/step - loss: 0.3235 - accuracy: 0.9533\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 596us/step - loss: 0.3227 - accuracy: 0.9600\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 758us/step - loss: 0.3217 - accuracy: 0.9667\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 587us/step - loss: 0.3209 - accuracy: 0.9667\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 546us/step - loss: 0.3199 - accuracy: 0.9667\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 686us/step - loss: 0.3191 - accuracy: 0.9667\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 544us/step - loss: 0.3184 - accuracy: 0.9667\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 520us/step - loss: 0.3174 - accuracy: 0.9667\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 519us/step - loss: 0.3166 - accuracy: 0.9667\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 538us/step - loss: 0.3162 - accuracy: 0.9667\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 561us/step - loss: 0.3148 - accuracy: 0.9667\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.3139 - accuracy: 0.9667\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 602us/step - loss: 0.3132 - accuracy: 0.9667\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 528us/step - loss: 0.3121 - accuracy: 0.9667\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 522us/step - loss: 0.3114 - accuracy: 0.9667\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 478us/step - loss: 0.3105 - accuracy: 0.9667\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 579us/step - loss: 0.3097 - accuracy: 0.9667\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 605us/step - loss: 0.3088 - accuracy: 0.9667\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 610us/step - loss: 0.3080 - accuracy: 0.9667\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 663us/step - loss: 0.3072 - accuracy: 0.9667\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 654us/step - loss: 0.3063 - accuracy: 0.9667\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 537us/step - loss: 0.3055 - accuracy: 0.9667\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 641us/step - loss: 0.3046 - accuracy: 0.9667\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 651us/step - loss: 0.3038 - accuracy: 0.9667\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 545us/step - loss: 0.3030 - accuracy: 0.9667\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 572us/step - loss: 0.3023 - accuracy: 0.9667\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 567us/step - loss: 0.3014 - accuracy: 0.9667\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 566us/step - loss: 0.3006 - accuracy: 0.9667\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 589us/step - loss: 0.2998 - accuracy: 0.9733\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 666us/step - loss: 0.2989 - accuracy: 0.9733\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 558us/step - loss: 0.2982 - accuracy: 0.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2e74588c70>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X, y, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que ahora hemos obtenido una precisión del 97%, es mayor que la obtuvimos antes.\n",
    "# Pero la que obtuvimos antes es la válida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora tenemos que guardar el modelo\n",
    "model.save(\"final_iris_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora tenemos que guardar el Scaler\n",
    "import joblib\n",
    "joblib.dump(scaler, \"iris_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción sobre una simple flor\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el modelo\n",
    "flower_model = load_model(\"final_iris_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el scaler\n",
    "flower_scaler = joblib.load(\"iris_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hagamos una predicción."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

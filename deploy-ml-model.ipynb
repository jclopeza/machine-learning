{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv(\"datasets/iris/iris.csv\")\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('Species', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenemos un problema de clasificación múltiple\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos a cambiar nuestro array con los labels a 'one-hot-encoder'\n",
    "y = encoder.fit_transform(y)\n",
    "# Mostramos los 5 primeros. Hemos convertido las especies 'setosa', 'versicolor', 'virginica'\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test split y creación de un Scaler para los datos.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creación de un Scaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora transformamos los datos de train y test\n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tengamos en cuenta que tenemos que guardar el objeto scaler para poder luego utilizarlo en procesos sucesivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora tenemos que crear la red neuronal con Keras y TensorFlow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del modelo\n",
    "model = Sequential()\n",
    "# Capa de entrada\n",
    "model.add(Dense(units=4, activation='relu', input_shape=[4, ]))\n",
    "# Capa de salida\n",
    "model.add(Dense(units=3, activation='softmax'))  # Porque tenemos una función de clasificación múltiple\n",
    "# Compilamos el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregación de un early stopping para evitar overfitting\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.1472 - accuracy: 0.3333 - val_loss: 1.1594 - val_accuracy: 0.3333\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1388 - accuracy: 0.3333 - val_loss: 1.1515 - val_accuracy: 0.3333\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1327 - accuracy: 0.3333 - val_loss: 1.1438 - val_accuracy: 0.3333\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1257 - accuracy: 0.3333 - val_loss: 1.1369 - val_accuracy: 0.3333\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1199 - accuracy: 0.3333 - val_loss: 1.1304 - val_accuracy: 0.3333\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1143 - accuracy: 0.3333 - val_loss: 1.1242 - val_accuracy: 0.3333\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1099 - accuracy: 0.3333 - val_loss: 1.1183 - val_accuracy: 0.3333\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1048 - accuracy: 0.3333 - val_loss: 1.1130 - val_accuracy: 0.3333\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1002 - accuracy: 0.3333 - val_loss: 1.1083 - val_accuracy: 0.3333\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0962 - accuracy: 0.3333 - val_loss: 1.1037 - val_accuracy: 0.3333\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0922 - accuracy: 0.3333 - val_loss: 1.0994 - val_accuracy: 0.3333\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0883 - accuracy: 0.3333 - val_loss: 1.0952 - val_accuracy: 0.3333\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0846 - accuracy: 0.3333 - val_loss: 1.0911 - val_accuracy: 0.3333\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0810 - accuracy: 0.3333 - val_loss: 1.0872 - val_accuracy: 0.3333\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0775 - accuracy: 0.3333 - val_loss: 1.0833 - val_accuracy: 0.3333\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0741 - accuracy: 0.3333 - val_loss: 1.0794 - val_accuracy: 0.3333\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0706 - accuracy: 0.3417 - val_loss: 1.0757 - val_accuracy: 0.3333\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0673 - accuracy: 0.3417 - val_loss: 1.0720 - val_accuracy: 0.3333\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0640 - accuracy: 0.3500 - val_loss: 1.0685 - val_accuracy: 0.3333\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0608 - accuracy: 0.3583 - val_loss: 1.0650 - val_accuracy: 0.3333\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0576 - accuracy: 0.3667 - val_loss: 1.0617 - val_accuracy: 0.3333\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0543 - accuracy: 0.3667 - val_loss: 1.0584 - val_accuracy: 0.3667\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0512 - accuracy: 0.3667 - val_loss: 1.0552 - val_accuracy: 0.3667\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0480 - accuracy: 0.3833 - val_loss: 1.0519 - val_accuracy: 0.3667\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0449 - accuracy: 0.3917 - val_loss: 1.0487 - val_accuracy: 0.4333\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0418 - accuracy: 0.3917 - val_loss: 1.0456 - val_accuracy: 0.4333\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0388 - accuracy: 0.4000 - val_loss: 1.0425 - val_accuracy: 0.4333\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0357 - accuracy: 0.4083 - val_loss: 1.0394 - val_accuracy: 0.4333\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0328 - accuracy: 0.4250 - val_loss: 1.0364 - val_accuracy: 0.4333\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0297 - accuracy: 0.4333 - val_loss: 1.0335 - val_accuracy: 0.4333\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0269 - accuracy: 0.4333 - val_loss: 1.0305 - val_accuracy: 0.4333\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0238 - accuracy: 0.4333 - val_loss: 1.0277 - val_accuracy: 0.4333\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0208 - accuracy: 0.4583 - val_loss: 1.0248 - val_accuracy: 0.4333\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0178 - accuracy: 0.4667 - val_loss: 1.0219 - val_accuracy: 0.4667\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0148 - accuracy: 0.4833 - val_loss: 1.0190 - val_accuracy: 0.5000\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0118 - accuracy: 0.4917 - val_loss: 1.0163 - val_accuracy: 0.5000\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4917 - val_loss: 1.0135 - val_accuracy: 0.5000\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0058 - accuracy: 0.5000 - val_loss: 1.0107 - val_accuracy: 0.5000\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0028 - accuracy: 0.5083 - val_loss: 1.0080 - val_accuracy: 0.5000\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9999 - accuracy: 0.5333 - val_loss: 1.0051 - val_accuracy: 0.5000\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9969 - accuracy: 0.5417 - val_loss: 1.0023 - val_accuracy: 0.5333\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9941 - accuracy: 0.5583 - val_loss: 0.9994 - val_accuracy: 0.5333\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9910 - accuracy: 0.5583 - val_loss: 0.9966 - val_accuracy: 0.5333\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9881 - accuracy: 0.5667 - val_loss: 0.9937 - val_accuracy: 0.5333\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9852 - accuracy: 0.5750 - val_loss: 0.9909 - val_accuracy: 0.5333\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9824 - accuracy: 0.5750 - val_loss: 0.9880 - val_accuracy: 0.5333\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9792 - accuracy: 0.5750 - val_loss: 0.9852 - val_accuracy: 0.5333\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9763 - accuracy: 0.5833 - val_loss: 0.9824 - val_accuracy: 0.5333\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9734 - accuracy: 0.5833 - val_loss: 0.9795 - val_accuracy: 0.5333\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9704 - accuracy: 0.6000 - val_loss: 0.9767 - val_accuracy: 0.5667\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9675 - accuracy: 0.6000 - val_loss: 0.9739 - val_accuracy: 0.5667\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9646 - accuracy: 0.5833 - val_loss: 0.9711 - val_accuracy: 0.5667\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9617 - accuracy: 0.5917 - val_loss: 0.9682 - val_accuracy: 0.5667\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9588 - accuracy: 0.5917 - val_loss: 0.9655 - val_accuracy: 0.5667\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9559 - accuracy: 0.5917 - val_loss: 0.9627 - val_accuracy: 0.5667\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9531 - accuracy: 0.5917 - val_loss: 0.9599 - val_accuracy: 0.5667\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9503 - accuracy: 0.5917 - val_loss: 0.9571 - val_accuracy: 0.5667\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9474 - accuracy: 0.5917 - val_loss: 0.9543 - val_accuracy: 0.5667\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9445 - accuracy: 0.5917 - val_loss: 0.9514 - val_accuracy: 0.5667\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9416 - accuracy: 0.5917 - val_loss: 0.9486 - val_accuracy: 0.5667\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9387 - accuracy: 0.5917 - val_loss: 0.9458 - val_accuracy: 0.5667\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9358 - accuracy: 0.5917 - val_loss: 0.9430 - val_accuracy: 0.5667\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9329 - accuracy: 0.5917 - val_loss: 0.9403 - val_accuracy: 0.5667\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9302 - accuracy: 0.5917 - val_loss: 0.9375 - val_accuracy: 0.5667\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9272 - accuracy: 0.5917 - val_loss: 0.9347 - val_accuracy: 0.6000\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9244 - accuracy: 0.5917 - val_loss: 0.9319 - val_accuracy: 0.6000\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9215 - accuracy: 0.5917 - val_loss: 0.9292 - val_accuracy: 0.6000\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9186 - accuracy: 0.5917 - val_loss: 0.9264 - val_accuracy: 0.6000\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9157 - accuracy: 0.6000 - val_loss: 0.9237 - val_accuracy: 0.6000\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9128 - accuracy: 0.6000 - val_loss: 0.9209 - val_accuracy: 0.6000\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9099 - accuracy: 0.6000 - val_loss: 0.9181 - val_accuracy: 0.6000\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9072 - accuracy: 0.6000 - val_loss: 0.9153 - val_accuracy: 0.6000\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9043 - accuracy: 0.6000 - val_loss: 0.9125 - val_accuracy: 0.6000\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9013 - accuracy: 0.6000 - val_loss: 0.9097 - val_accuracy: 0.6000\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8986 - accuracy: 0.6000 - val_loss: 0.9069 - val_accuracy: 0.6000\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8957 - accuracy: 0.6000 - val_loss: 0.9041 - val_accuracy: 0.6000\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8929 - accuracy: 0.6000 - val_loss: 0.9014 - val_accuracy: 0.6000\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8900 - accuracy: 0.6083 - val_loss: 0.8987 - val_accuracy: 0.6000\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8872 - accuracy: 0.6083 - val_loss: 0.8959 - val_accuracy: 0.6000\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8844 - accuracy: 0.6083 - val_loss: 0.8932 - val_accuracy: 0.6000\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8816 - accuracy: 0.6083 - val_loss: 0.8905 - val_accuracy: 0.6000\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8788 - accuracy: 0.6083 - val_loss: 0.8877 - val_accuracy: 0.6000\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8761 - accuracy: 0.6083 - val_loss: 0.8850 - val_accuracy: 0.6000\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8732 - accuracy: 0.6083 - val_loss: 0.8822 - val_accuracy: 0.6333\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8704 - accuracy: 0.6083 - val_loss: 0.8795 - val_accuracy: 0.6333\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8677 - accuracy: 0.6083 - val_loss: 0.8767 - val_accuracy: 0.6333\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8649 - accuracy: 0.6083 - val_loss: 0.8740 - val_accuracy: 0.6333\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8622 - accuracy: 0.6083 - val_loss: 0.8712 - val_accuracy: 0.6333\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8594 - accuracy: 0.6083 - val_loss: 0.8685 - val_accuracy: 0.6333\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8566 - accuracy: 0.6167 - val_loss: 0.8659 - val_accuracy: 0.6333\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8539 - accuracy: 0.6167 - val_loss: 0.8632 - val_accuracy: 0.6333\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8512 - accuracy: 0.6167 - val_loss: 0.8605 - val_accuracy: 0.6333\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8485 - accuracy: 0.6167 - val_loss: 0.8578 - val_accuracy: 0.6333\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8458 - accuracy: 0.6167 - val_loss: 0.8551 - val_accuracy: 0.6333\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8431 - accuracy: 0.6167 - val_loss: 0.8524 - val_accuracy: 0.6333\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8404 - accuracy: 0.6250 - val_loss: 0.8498 - val_accuracy: 0.6333\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8377 - accuracy: 0.6250 - val_loss: 0.8471 - val_accuracy: 0.6333\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8350 - accuracy: 0.6250 - val_loss: 0.8445 - val_accuracy: 0.6333\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8324 - accuracy: 0.6250 - val_loss: 0.8418 - val_accuracy: 0.6333\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8297 - accuracy: 0.6250 - val_loss: 0.8392 - val_accuracy: 0.6333\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8270 - accuracy: 0.6333 - val_loss: 0.8367 - val_accuracy: 0.6333\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8244 - accuracy: 0.6333 - val_loss: 0.8340 - val_accuracy: 0.6333\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8218 - accuracy: 0.6333 - val_loss: 0.8314 - val_accuracy: 0.6333\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8191 - accuracy: 0.6333 - val_loss: 0.8290 - val_accuracy: 0.6333\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8165 - accuracy: 0.6333 - val_loss: 0.8265 - val_accuracy: 0.6333\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8140 - accuracy: 0.6333 - val_loss: 0.8239 - val_accuracy: 0.6333\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8113 - accuracy: 0.6333 - val_loss: 0.8214 - val_accuracy: 0.6333\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8088 - accuracy: 0.6333 - val_loss: 0.8189 - val_accuracy: 0.6333\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8061 - accuracy: 0.6500 - val_loss: 0.8164 - val_accuracy: 0.6333\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8036 - accuracy: 0.6583 - val_loss: 0.8139 - val_accuracy: 0.6333\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8010 - accuracy: 0.6583 - val_loss: 0.8114 - val_accuracy: 0.6333\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7985 - accuracy: 0.6583 - val_loss: 0.8089 - val_accuracy: 0.6333\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7961 - accuracy: 0.6583 - val_loss: 0.8064 - val_accuracy: 0.6333\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7935 - accuracy: 0.6583 - val_loss: 0.8040 - val_accuracy: 0.6333\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7911 - accuracy: 0.6583 - val_loss: 0.8015 - val_accuracy: 0.6333\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7886 - accuracy: 0.6667 - val_loss: 0.7991 - val_accuracy: 0.6333\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7862 - accuracy: 0.6667 - val_loss: 0.7966 - val_accuracy: 0.6333\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7838 - accuracy: 0.6667 - val_loss: 0.7942 - val_accuracy: 0.6333\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7814 - accuracy: 0.6667 - val_loss: 0.7918 - val_accuracy: 0.6333\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7790 - accuracy: 0.6667 - val_loss: 0.7895 - val_accuracy: 0.6333\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7766 - accuracy: 0.6750 - val_loss: 0.7872 - val_accuracy: 0.6333\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7743 - accuracy: 0.6750 - val_loss: 0.7849 - val_accuracy: 0.6333\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7720 - accuracy: 0.6750 - val_loss: 0.7826 - val_accuracy: 0.6333\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7697 - accuracy: 0.6750 - val_loss: 0.7803 - val_accuracy: 0.6333\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7674 - accuracy: 0.6750 - val_loss: 0.7780 - val_accuracy: 0.6333\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7651 - accuracy: 0.6750 - val_loss: 0.7757 - val_accuracy: 0.6333\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7628 - accuracy: 0.6750 - val_loss: 0.7734 - val_accuracy: 0.6333\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7606 - accuracy: 0.6750 - val_loss: 0.7711 - val_accuracy: 0.6333\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7584 - accuracy: 0.6750 - val_loss: 0.7688 - val_accuracy: 0.6333\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7562 - accuracy: 0.6750 - val_loss: 0.7666 - val_accuracy: 0.6333\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7540 - accuracy: 0.6750 - val_loss: 0.7644 - val_accuracy: 0.6333\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7518 - accuracy: 0.6750 - val_loss: 0.7622 - val_accuracy: 0.6333\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7496 - accuracy: 0.6750 - val_loss: 0.7600 - val_accuracy: 0.6333\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7475 - accuracy: 0.6750 - val_loss: 0.7579 - val_accuracy: 0.6333\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7454 - accuracy: 0.6750 - val_loss: 0.7557 - val_accuracy: 0.6333\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7433 - accuracy: 0.6750 - val_loss: 0.7537 - val_accuracy: 0.6333\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7412 - accuracy: 0.6750 - val_loss: 0.7515 - val_accuracy: 0.6333\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.6750 - val_loss: 0.7494 - val_accuracy: 0.6333\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.6750 - val_loss: 0.7473 - val_accuracy: 0.6333\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.6750 - val_loss: 0.7452 - val_accuracy: 0.6333\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7330 - accuracy: 0.6750 - val_loss: 0.7432 - val_accuracy: 0.6333\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7310 - accuracy: 0.6750 - val_loss: 0.7412 - val_accuracy: 0.6333\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7291 - accuracy: 0.6750 - val_loss: 0.7392 - val_accuracy: 0.6333\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7271 - accuracy: 0.6750 - val_loss: 0.7372 - val_accuracy: 0.6333\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7252 - accuracy: 0.6750 - val_loss: 0.7351 - val_accuracy: 0.6333\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7232 - accuracy: 0.6750 - val_loss: 0.7332 - val_accuracy: 0.6333\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7213 - accuracy: 0.6750 - val_loss: 0.7313 - val_accuracy: 0.6333\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7194 - accuracy: 0.6750 - val_loss: 0.7294 - val_accuracy: 0.6333\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7175 - accuracy: 0.6750 - val_loss: 0.7275 - val_accuracy: 0.6333\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7156 - accuracy: 0.6750 - val_loss: 0.7256 - val_accuracy: 0.6333\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7138 - accuracy: 0.6750 - val_loss: 0.7238 - val_accuracy: 0.6333\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7119 - accuracy: 0.6750 - val_loss: 0.7219 - val_accuracy: 0.6333\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7101 - accuracy: 0.6750 - val_loss: 0.7200 - val_accuracy: 0.6333\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7083 - accuracy: 0.6750 - val_loss: 0.7181 - val_accuracy: 0.6333\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7066 - accuracy: 0.6750 - val_loss: 0.7163 - val_accuracy: 0.6333\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7048 - accuracy: 0.6750 - val_loss: 0.7145 - val_accuracy: 0.6333\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7031 - accuracy: 0.6750 - val_loss: 0.7126 - val_accuracy: 0.6333\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7014 - accuracy: 0.6750 - val_loss: 0.7109 - val_accuracy: 0.6333\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6996 - accuracy: 0.6750 - val_loss: 0.7091 - val_accuracy: 0.6333\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6979 - accuracy: 0.6750 - val_loss: 0.7073 - val_accuracy: 0.6333\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6963 - accuracy: 0.6750 - val_loss: 0.7056 - val_accuracy: 0.6333\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.6750 - val_loss: 0.7039 - val_accuracy: 0.6333\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.6750 - val_loss: 0.7021 - val_accuracy: 0.6333\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.6750 - val_loss: 0.7004 - val_accuracy: 0.6333\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.6750 - val_loss: 0.6988 - val_accuracy: 0.6333\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.6750 - val_loss: 0.6971 - val_accuracy: 0.6333\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.6750 - val_loss: 0.6955 - val_accuracy: 0.6333\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.6750 - val_loss: 0.6938 - val_accuracy: 0.6333\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.6750 - val_loss: 0.6922 - val_accuracy: 0.6333\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6818 - accuracy: 0.6750 - val_loss: 0.6906 - val_accuracy: 0.6333\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6803 - accuracy: 0.6750 - val_loss: 0.6889 - val_accuracy: 0.6333\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6788 - accuracy: 0.6750 - val_loss: 0.6874 - val_accuracy: 0.6333\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.6750 - val_loss: 0.6858 - val_accuracy: 0.6333\n",
      "Epoch 174/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6758 - accuracy: 0.6750 - val_loss: 0.6843 - val_accuracy: 0.6333\n",
      "Epoch 175/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.6750 - val_loss: 0.6828 - val_accuracy: 0.6333\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.6750 - val_loss: 0.6813 - val_accuracy: 0.6333\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6750 - val_loss: 0.6798 - val_accuracy: 0.6333\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.6750 - val_loss: 0.6783 - val_accuracy: 0.6333\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.6750 - val_loss: 0.6768 - val_accuracy: 0.6333\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6670 - accuracy: 0.6750 - val_loss: 0.6754 - val_accuracy: 0.6333\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6655 - accuracy: 0.6750 - val_loss: 0.6740 - val_accuracy: 0.6333\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6641 - accuracy: 0.6750 - val_loss: 0.6726 - val_accuracy: 0.6333\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.6750 - val_loss: 0.6712 - val_accuracy: 0.6333\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6614 - accuracy: 0.6750 - val_loss: 0.6698 - val_accuracy: 0.6333\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6600 - accuracy: 0.6750 - val_loss: 0.6684 - val_accuracy: 0.6333\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6586 - accuracy: 0.6750 - val_loss: 0.6670 - val_accuracy: 0.6333\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.6750 - val_loss: 0.6656 - val_accuracy: 0.6333\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.6750 - val_loss: 0.6643 - val_accuracy: 0.6333\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6546 - accuracy: 0.6750 - val_loss: 0.6630 - val_accuracy: 0.6333\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.6750 - val_loss: 0.6617 - val_accuracy: 0.6333\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.6750 - val_loss: 0.6603 - val_accuracy: 0.6333\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6750 - val_loss: 0.6591 - val_accuracy: 0.6333\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.6750 - val_loss: 0.6577 - val_accuracy: 0.6333\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.6750 - val_loss: 0.6565 - val_accuracy: 0.6333\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.6750 - val_loss: 0.6552 - val_accuracy: 0.6333\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.6750 - val_loss: 0.6539 - val_accuracy: 0.6333\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6444 - accuracy: 0.6750 - val_loss: 0.6527 - val_accuracy: 0.6333\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.6750 - val_loss: 0.6515 - val_accuracy: 0.6333\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.6750 - val_loss: 0.6503 - val_accuracy: 0.6333\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.6750 - val_loss: 0.6492 - val_accuracy: 0.6333\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.6750 - val_loss: 0.6480 - val_accuracy: 0.6333\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.6750 - val_loss: 0.6468 - val_accuracy: 0.6333\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.6750 - val_loss: 0.6456 - val_accuracy: 0.6333\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.6750 - val_loss: 0.6444 - val_accuracy: 0.6333\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.6750 - val_loss: 0.6433 - val_accuracy: 0.6333\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6337 - accuracy: 0.6750 - val_loss: 0.6422 - val_accuracy: 0.6333\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.6750 - val_loss: 0.6410 - val_accuracy: 0.6333\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.6750 - val_loss: 0.6399 - val_accuracy: 0.6333\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.6750 - val_loss: 0.6388 - val_accuracy: 0.6333\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6293 - accuracy: 0.6750 - val_loss: 0.6376 - val_accuracy: 0.6333\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6282 - accuracy: 0.6750 - val_loss: 0.6365 - val_accuracy: 0.6333\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.6750 - val_loss: 0.6354 - val_accuracy: 0.6333\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.6750 - val_loss: 0.6343 - val_accuracy: 0.6333\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.6750 - val_loss: 0.6331 - val_accuracy: 0.6333\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6240 - accuracy: 0.6750 - val_loss: 0.6320 - val_accuracy: 0.6333\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.6750 - val_loss: 0.6310 - val_accuracy: 0.6333\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.6750 - val_loss: 0.6299 - val_accuracy: 0.6333\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6209 - accuracy: 0.6750 - val_loss: 0.6288 - val_accuracy: 0.6333\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.6750 - val_loss: 0.6278 - val_accuracy: 0.6333\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6189 - accuracy: 0.6750 - val_loss: 0.6267 - val_accuracy: 0.6333\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6179 - accuracy: 0.6750 - val_loss: 0.6257 - val_accuracy: 0.6333\n",
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.6750 - val_loss: 0.6247 - val_accuracy: 0.6333\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.6750 - val_loss: 0.6236 - val_accuracy: 0.6333\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.6750 - val_loss: 0.6226 - val_accuracy: 0.6333\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6140 - accuracy: 0.6750 - val_loss: 0.6217 - val_accuracy: 0.6333\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.6750 - val_loss: 0.6207 - val_accuracy: 0.6333\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.6750 - val_loss: 0.6197 - val_accuracy: 0.6333\n",
      "Epoch 228/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.6750 - val_loss: 0.6187 - val_accuracy: 0.6333\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.6750 - val_loss: 0.6178 - val_accuracy: 0.6333\n",
      "Epoch 230/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6094 - accuracy: 0.6750 - val_loss: 0.6168 - val_accuracy: 0.6333\n",
      "Epoch 231/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6750 - val_loss: 0.6158 - val_accuracy: 0.6333\n",
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6075 - accuracy: 0.6750 - val_loss: 0.6150 - val_accuracy: 0.6333\n",
      "Epoch 233/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6066 - accuracy: 0.6750 - val_loss: 0.6140 - val_accuracy: 0.6333\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6057 - accuracy: 0.6750 - val_loss: 0.6131 - val_accuracy: 0.6333\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.6750 - val_loss: 0.6122 - val_accuracy: 0.6333\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.6750 - val_loss: 0.6114 - val_accuracy: 0.6333\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.6750 - val_loss: 0.6105 - val_accuracy: 0.6333\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.6750 - val_loss: 0.6095 - val_accuracy: 0.6333\n",
      "Epoch 239/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.6750 - val_loss: 0.6086 - val_accuracy: 0.6333\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.6750 - val_loss: 0.6077 - val_accuracy: 0.6333\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.6750 - val_loss: 0.6069 - val_accuracy: 0.6333\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.6750 - val_loss: 0.6060 - val_accuracy: 0.6333\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.6750 - val_loss: 0.6052 - val_accuracy: 0.6333\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.6750 - val_loss: 0.6043 - val_accuracy: 0.6333\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.6750 - val_loss: 0.6035 - val_accuracy: 0.6333\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.6750 - val_loss: 0.6027 - val_accuracy: 0.6333\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.6750 - val_loss: 0.6018 - val_accuracy: 0.6333\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.6750 - val_loss: 0.6010 - val_accuracy: 0.6333\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.6750 - val_loss: 0.6002 - val_accuracy: 0.6333\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.6750 - val_loss: 0.5994 - val_accuracy: 0.6333\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.6750 - val_loss: 0.5985 - val_accuracy: 0.6333\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.6750 - val_loss: 0.5977 - val_accuracy: 0.6333\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.6750 - val_loss: 0.5970 - val_accuracy: 0.6333\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.6750 - val_loss: 0.5962 - val_accuracy: 0.6333\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.6750 - val_loss: 0.5953 - val_accuracy: 0.6333\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.6750 - val_loss: 0.5946 - val_accuracy: 0.6333\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.6750 - val_loss: 0.5938 - val_accuracy: 0.6333\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.6750 - val_loss: 0.5931 - val_accuracy: 0.6333\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.6750 - val_loss: 0.5923 - val_accuracy: 0.6333\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5848 - accuracy: 0.6750 - val_loss: 0.5916 - val_accuracy: 0.6333\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5841 - accuracy: 0.6750 - val_loss: 0.5908 - val_accuracy: 0.6333\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.6750 - val_loss: 0.5901 - val_accuracy: 0.6333\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.6750 - val_loss: 0.5894 - val_accuracy: 0.6333\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.6750 - val_loss: 0.5886 - val_accuracy: 0.6333\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.6750 - val_loss: 0.5878 - val_accuracy: 0.6333\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.6750 - val_loss: 0.5871 - val_accuracy: 0.6333\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.6750 - val_loss: 0.5864 - val_accuracy: 0.6333\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.6750 - val_loss: 0.5857 - val_accuracy: 0.6333\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.6750 - val_loss: 0.5849 - val_accuracy: 0.6333\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.6750 - val_loss: 0.5842 - val_accuracy: 0.6333\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.6750 - val_loss: 0.5835 - val_accuracy: 0.6333\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.6750 - val_loss: 0.5828 - val_accuracy: 0.6333\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.6750 - val_loss: 0.5821 - val_accuracy: 0.6333\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.6750 - val_loss: 0.5813 - val_accuracy: 0.6333\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.6750 - val_loss: 0.5807 - val_accuracy: 0.6333\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.6750 - val_loss: 0.5799 - val_accuracy: 0.6333\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.6750 - val_loss: 0.5793 - val_accuracy: 0.6333\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.6750 - val_loss: 0.5785 - val_accuracy: 0.6333\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.6750 - val_loss: 0.5778 - val_accuracy: 0.6333\n",
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.6750 - val_loss: 0.5771 - val_accuracy: 0.6333\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.6750 - val_loss: 0.5764 - val_accuracy: 0.6333\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.6750 - val_loss: 0.5758 - val_accuracy: 0.6333\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.6750 - val_loss: 0.5751 - val_accuracy: 0.6333\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5676 - accuracy: 0.6750 - val_loss: 0.5744 - val_accuracy: 0.6333\n",
      "Epoch 285/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.6750 - val_loss: 0.5737 - val_accuracy: 0.6333\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.6750 - val_loss: 0.5729 - val_accuracy: 0.6333\n",
      "Epoch 287/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.6750 - val_loss: 0.5722 - val_accuracy: 0.6333\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.6750 - val_loss: 0.5715 - val_accuracy: 0.6333\n",
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.6750 - val_loss: 0.5708 - val_accuracy: 0.6333\n",
      "Epoch 290/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.6750 - val_loss: 0.5701 - val_accuracy: 0.6333\n",
      "Epoch 291/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.6750 - val_loss: 0.5694 - val_accuracy: 0.6333\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.6750 - val_loss: 0.5687 - val_accuracy: 0.6333\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.6750 - val_loss: 0.5680 - val_accuracy: 0.6333\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5604 - accuracy: 0.6750 - val_loss: 0.5673 - val_accuracy: 0.6333\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.6750 - val_loss: 0.5666 - val_accuracy: 0.6333\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5589 - accuracy: 0.6750 - val_loss: 0.5659 - val_accuracy: 0.6333\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.6750 - val_loss: 0.5652 - val_accuracy: 0.6333\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.6750 - val_loss: 0.5644 - val_accuracy: 0.6333\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.6750 - val_loss: 0.5636 - val_accuracy: 0.6333\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.6750 - val_loss: 0.5629 - val_accuracy: 0.6333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f75107b7220>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento del modelo\n",
    "model.fit(x=scaled_X_train, y=y_train, epochs=300,\n",
    "         validation_data=(scaled_X_test, y_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.147242</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.159443</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.138818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.151510</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.132742</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.143791</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.125677</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.136894</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.119872</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.130350</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.558922</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.565875</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.558191</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.565184</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.557400</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.564403</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.556653</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.563624</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.555930</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.562891</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    1.147242  0.333333  1.159443      0.333333\n",
       "1    1.138818  0.333333  1.151510      0.333333\n",
       "2    1.132742  0.333333  1.143791      0.333333\n",
       "3    1.125677  0.333333  1.136894      0.333333\n",
       "4    1.119872  0.333333  1.130350      0.333333\n",
       "..        ...       ...       ...           ...\n",
       "295  0.558922  0.675000  0.565875      0.633333\n",
       "296  0.558191  0.675000  0.565184      0.633333\n",
       "297  0.557400  0.675000  0.564403      0.633333\n",
       "298  0.556653  0.675000  0.563624      0.633333\n",
       "299  0.555930  0.675000  0.562891      0.633333\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estudiemos las métricas\n",
    "metrics = pd.DataFrame(model.history.history)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f75107bf430>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dibujemos en un gráfico las funciones loss y val_loss\n",
    "metrics[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f74c4076490>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dibujemos en un gráfico las funciones accuracy y val_accuracy\n",
    "metrics[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5628907084465027, 0.6333333253860474]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluación del modelo\n",
    "model.evaluate(scaled_X_test, y_test, verbose=0) # Lo que obtendremos es el final_loss y el final_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí es el punto en el que tenemos que decidir si estas métricas son lo suficientemente buenas\n",
    "# Hemos obtenido el 80% de precisión. ¿Es suficiente? -> Sí, entonces ...\n",
    "# Preparemos nuestro modelo para el deployment.\n",
    "# Lo que quiero es conseguir el mejor modelo posible. Para ello, utilizo ahora todos los datos.\n",
    "# Voy a aplicar nuestro Scaler a todos los datos\n",
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos ahora un nuevo modelo usando todos los datos\n",
    "model = Sequential()\n",
    "model.add(Dense(units=4, activation='relu', input_shape=[4, ]))\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 0s 708us/step - loss: 1.0514 - accuracy: 0.6667\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 574us/step - loss: 1.0497 - accuracy: 0.6667\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 556us/step - loss: 1.0480 - accuracy: 0.4000\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 653us/step - loss: 1.0465 - accuracy: 0.3333\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 505us/step - loss: 1.0449 - accuracy: 0.3333\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 568us/step - loss: 1.0433 - accuracy: 0.3333\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 543us/step - loss: 1.0416 - accuracy: 0.3333\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 588us/step - loss: 1.0399 - accuracy: 0.3333\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 446us/step - loss: 1.0382 - accuracy: 0.3333\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 672us/step - loss: 1.0364 - accuracy: 0.3333\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 635us/step - loss: 1.0346 - accuracy: 0.3333\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 532us/step - loss: 1.0327 - accuracy: 0.3333\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 592us/step - loss: 1.0309 - accuracy: 0.3333\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 531us/step - loss: 1.0289 - accuracy: 0.3333\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 490us/step - loss: 1.0270 - accuracy: 0.3333\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 490us/step - loss: 1.0250 - accuracy: 0.3333\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 507us/step - loss: 1.0229 - accuracy: 0.3333\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 501us/step - loss: 1.0209 - accuracy: 0.3333\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 567us/step - loss: 1.0187 - accuracy: 0.3333\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 538us/step - loss: 1.0165 - accuracy: 0.3333\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 620us/step - loss: 1.0144 - accuracy: 0.3333\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 743us/step - loss: 1.0122 - accuracy: 0.3333\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 619us/step - loss: 1.0099 - accuracy: 0.3333\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 550us/step - loss: 1.0076 - accuracy: 0.3333\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 653us/step - loss: 1.0054 - accuracy: 0.3333\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 495us/step - loss: 1.0032 - accuracy: 0.3333\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 522us/step - loss: 1.0006 - accuracy: 0.3333\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 556us/step - loss: 0.9983 - accuracy: 0.3333\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 584us/step - loss: 0.9958 - accuracy: 0.3333\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 637us/step - loss: 0.9936 - accuracy: 0.3333\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 540us/step - loss: 0.9910 - accuracy: 0.3333\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 658us/step - loss: 0.9885 - accuracy: 0.3333\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 616us/step - loss: 0.9859 - accuracy: 0.3333\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 539us/step - loss: 0.9834 - accuracy: 0.3333\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 642us/step - loss: 0.9808 - accuracy: 0.3333\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 520us/step - loss: 0.9782 - accuracy: 0.3333\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 573us/step - loss: 0.9756 - accuracy: 0.5933\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 604us/step - loss: 0.9731 - accuracy: 0.6600\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 656us/step - loss: 0.9703 - accuracy: 0.6600\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 716us/step - loss: 0.9676 - accuracy: 0.6600\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 556us/step - loss: 0.9649 - accuracy: 0.6600\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 543us/step - loss: 0.9622 - accuracy: 0.6600\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 613us/step - loss: 0.9595 - accuracy: 0.6600\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 509us/step - loss: 0.9569 - accuracy: 0.6600\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 553us/step - loss: 0.9541 - accuracy: 0.6600\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.9515 - accuracy: 0.6600\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 618us/step - loss: 0.9488 - accuracy: 0.6600\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 533us/step - loss: 0.9461 - accuracy: 0.6600\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 595us/step - loss: 0.9435 - accuracy: 0.6600\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 507us/step - loss: 0.9408 - accuracy: 0.6600\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 521us/step - loss: 0.9381 - accuracy: 0.6600\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 537us/step - loss: 0.9355 - accuracy: 0.6600\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 521us/step - loss: 0.9329 - accuracy: 0.6600\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 618us/step - loss: 0.9302 - accuracy: 0.6600\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 540us/step - loss: 0.9275 - accuracy: 0.6600\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 630us/step - loss: 0.9250 - accuracy: 0.6600\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 578us/step - loss: 0.9223 - accuracy: 0.6600\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 628us/step - loss: 0.9197 - accuracy: 0.6600\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 540us/step - loss: 0.9171 - accuracy: 0.6600\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 661us/step - loss: 0.9145 - accuracy: 0.6667\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 633us/step - loss: 0.9118 - accuracy: 0.6667\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 527us/step - loss: 0.9092 - accuracy: 0.6667\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 548us/step - loss: 0.9067 - accuracy: 0.6667\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.9040 - accuracy: 0.6667\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 529us/step - loss: 0.9015 - accuracy: 0.6667\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 624us/step - loss: 0.8989 - accuracy: 0.6667\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 502us/step - loss: 0.8963 - accuracy: 0.6667\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 513us/step - loss: 0.8937 - accuracy: 0.6667\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 606us/step - loss: 0.8912 - accuracy: 0.6667\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 597us/step - loss: 0.8885 - accuracy: 0.6667\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 564us/step - loss: 0.8860 - accuracy: 0.6667\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 508us/step - loss: 0.8834 - accuracy: 0.6667\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 625us/step - loss: 0.8808 - accuracy: 0.6667\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 543us/step - loss: 0.8783 - accuracy: 0.6667\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 481us/step - loss: 0.8757 - accuracy: 0.6667\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 481us/step - loss: 0.8731 - accuracy: 0.6667\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 603us/step - loss: 0.8706 - accuracy: 0.6667\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 586us/step - loss: 0.8680 - accuracy: 0.6667\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 479us/step - loss: 0.8655 - accuracy: 0.6667\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 533us/step - loss: 0.8629 - accuracy: 0.6667\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 512us/step - loss: 0.8604 - accuracy: 0.6667\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 503us/step - loss: 0.8579 - accuracy: 0.6667\n",
      "Epoch 83/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 518us/step - loss: 0.8554 - accuracy: 0.6667\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 486us/step - loss: 0.8529 - accuracy: 0.6667\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 469us/step - loss: 0.8503 - accuracy: 0.6667\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 555us/step - loss: 0.8478 - accuracy: 0.6667\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 537us/step - loss: 0.8453 - accuracy: 0.6667\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 516us/step - loss: 0.8428 - accuracy: 0.6667\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 519us/step - loss: 0.8404 - accuracy: 0.6667\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 528us/step - loss: 0.8378 - accuracy: 0.6667\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 508us/step - loss: 0.8354 - accuracy: 0.6667\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 700us/step - loss: 0.8329 - accuracy: 0.6667\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 581us/step - loss: 0.8304 - accuracy: 0.6667\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 532us/step - loss: 0.8280 - accuracy: 0.6667\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 567us/step - loss: 0.8255 - accuracy: 0.6667\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 539us/step - loss: 0.8231 - accuracy: 0.6667\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 502us/step - loss: 0.8206 - accuracy: 0.6667\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 609us/step - loss: 0.8183 - accuracy: 0.6667\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 558us/step - loss: 0.8158 - accuracy: 0.6667\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 500us/step - loss: 0.8134 - accuracy: 0.6667\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 640us/step - loss: 0.8110 - accuracy: 0.6667\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 474us/step - loss: 0.8086 - accuracy: 0.6667\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 470us/step - loss: 0.8062 - accuracy: 0.6667\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 522us/step - loss: 0.8038 - accuracy: 0.6667\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 521us/step - loss: 0.8015 - accuracy: 0.6667\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 472us/step - loss: 0.7991 - accuracy: 0.6667\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 461us/step - loss: 0.7967 - accuracy: 0.6667\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 481us/step - loss: 0.7944 - accuracy: 0.6667\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 488us/step - loss: 0.7921 - accuracy: 0.6667\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 590us/step - loss: 0.7898 - accuracy: 0.6667\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 579us/step - loss: 0.7875 - accuracy: 0.6667\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 576us/step - loss: 0.7852 - accuracy: 0.6667\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 585us/step - loss: 0.7829 - accuracy: 0.6667\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 660us/step - loss: 0.7807 - accuracy: 0.6667\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 507us/step - loss: 0.7784 - accuracy: 0.6733\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 531us/step - loss: 0.7761 - accuracy: 0.6733\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 592us/step - loss: 0.7739 - accuracy: 0.6800\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 493us/step - loss: 0.7717 - accuracy: 0.6800\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 527us/step - loss: 0.7695 - accuracy: 0.6800\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 527us/step - loss: 0.7673 - accuracy: 0.6800\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 620us/step - loss: 0.7650 - accuracy: 0.6800\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 569us/step - loss: 0.7628 - accuracy: 0.6800\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 607us/step - loss: 0.7607 - accuracy: 0.6800\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 554us/step - loss: 0.7585 - accuracy: 0.6867\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 572us/step - loss: 0.7563 - accuracy: 0.6867\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 549us/step - loss: 0.7542 - accuracy: 0.6867\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 500us/step - loss: 0.7520 - accuracy: 0.6867\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 570us/step - loss: 0.7499 - accuracy: 0.6867\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 519us/step - loss: 0.7478 - accuracy: 0.6867\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 577us/step - loss: 0.7456 - accuracy: 0.6867\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 465us/step - loss: 0.7436 - accuracy: 0.6867\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 553us/step - loss: 0.7414 - accuracy: 0.6867\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 520us/step - loss: 0.7394 - accuracy: 0.6867\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.7373 - accuracy: 0.6867\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 520us/step - loss: 0.7352 - accuracy: 0.6867\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 520us/step - loss: 0.7332 - accuracy: 0.6867\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 574us/step - loss: 0.7312 - accuracy: 0.6867\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 619us/step - loss: 0.7292 - accuracy: 0.6867\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 639us/step - loss: 0.7271 - accuracy: 0.6867\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 532us/step - loss: 0.7251 - accuracy: 0.6867\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 509us/step - loss: 0.7231 - accuracy: 0.6867\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 513us/step - loss: 0.7211 - accuracy: 0.6867\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 560us/step - loss: 0.7192 - accuracy: 0.6867\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.7172 - accuracy: 0.6867\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 586us/step - loss: 0.7153 - accuracy: 0.6867\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 651us/step - loss: 0.7133 - accuracy: 0.6867\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 633us/step - loss: 0.7114 - accuracy: 0.6867\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 569us/step - loss: 0.7096 - accuracy: 0.6867\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 680us/step - loss: 0.7076 - accuracy: 0.6867\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 530us/step - loss: 0.7057 - accuracy: 0.6933\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 515us/step - loss: 0.7039 - accuracy: 0.6933\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 603us/step - loss: 0.7020 - accuracy: 0.6933\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 729us/step - loss: 0.7001 - accuracy: 0.6933\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 717us/step - loss: 0.6983 - accuracy: 0.6933\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 575us/step - loss: 0.6965 - accuracy: 0.6933\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 547us/step - loss: 0.6947 - accuracy: 0.6933\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 523us/step - loss: 0.6929 - accuracy: 0.6933\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 520us/step - loss: 0.6911 - accuracy: 0.7000\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 619us/step - loss: 0.6893 - accuracy: 0.7000\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 610us/step - loss: 0.6875 - accuracy: 0.7000\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 522us/step - loss: 0.6857 - accuracy: 0.7000\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 665us/step - loss: 0.6840 - accuracy: 0.7000\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 657us/step - loss: 0.6823 - accuracy: 0.7000\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 524us/step - loss: 0.6805 - accuracy: 0.7000\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 654us/step - loss: 0.6788 - accuracy: 0.7000\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 529us/step - loss: 0.6771 - accuracy: 0.7000\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 548us/step - loss: 0.6754 - accuracy: 0.7067\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 641us/step - loss: 0.6737 - accuracy: 0.7067\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 577us/step - loss: 0.6719 - accuracy: 0.7067\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 634us/step - loss: 0.6703 - accuracy: 0.7067\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 521us/step - loss: 0.6686 - accuracy: 0.7067\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 506us/step - loss: 0.6670 - accuracy: 0.7067\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 541us/step - loss: 0.6653 - accuracy: 0.7067\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 472us/step - loss: 0.6637 - accuracy: 0.7133\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 560us/step - loss: 0.6621 - accuracy: 0.7133\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 602us/step - loss: 0.6605 - accuracy: 0.7133\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 449us/step - loss: 0.6588 - accuracy: 0.7133\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 595us/step - loss: 0.6572 - accuracy: 0.7133\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 622us/step - loss: 0.6556 - accuracy: 0.7133\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 584us/step - loss: 0.6541 - accuracy: 0.7133\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 595us/step - loss: 0.6525 - accuracy: 0.7133\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 516us/step - loss: 0.6509 - accuracy: 0.7133\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 698us/step - loss: 0.6496 - accuracy: 0.7133\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 570us/step - loss: 0.6479 - accuracy: 0.7133\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 603us/step - loss: 0.6464 - accuracy: 0.7133\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 549us/step - loss: 0.6449 - accuracy: 0.7133\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 586us/step - loss: 0.6433 - accuracy: 0.7133\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 548us/step - loss: 0.6418 - accuracy: 0.7133\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 595us/step - loss: 0.6404 - accuracy: 0.7133\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 540us/step - loss: 0.6389 - accuracy: 0.7133\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 579us/step - loss: 0.6374 - accuracy: 0.7200\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 548us/step - loss: 0.6360 - accuracy: 0.7267\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 666us/step - loss: 0.6346 - accuracy: 0.7333\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 592us/step - loss: 0.6331 - accuracy: 0.7333\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 537us/step - loss: 0.6317 - accuracy: 0.7333\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 694us/step - loss: 0.6302 - accuracy: 0.7333\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 520us/step - loss: 0.6288 - accuracy: 0.7333\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 585us/step - loss: 0.6274 - accuracy: 0.7333\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 697us/step - loss: 0.6260 - accuracy: 0.7400\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 716us/step - loss: 0.6246 - accuracy: 0.7400\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 634us/step - loss: 0.6232 - accuracy: 0.7400\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 587us/step - loss: 0.6219 - accuracy: 0.7400\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 669us/step - loss: 0.6205 - accuracy: 0.7400\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 646us/step - loss: 0.6192 - accuracy: 0.7400\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 685us/step - loss: 0.6178 - accuracy: 0.7533\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 585us/step - loss: 0.6164 - accuracy: 0.7533\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 713us/step - loss: 0.6151 - accuracy: 0.7533\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 757us/step - loss: 0.6138 - accuracy: 0.7533\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 582us/step - loss: 0.6124 - accuracy: 0.7533\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 545us/step - loss: 0.6113 - accuracy: 0.7533\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 641us/step - loss: 0.6098 - accuracy: 0.7533\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 510us/step - loss: 0.6086 - accuracy: 0.7533\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 537us/step - loss: 0.6073 - accuracy: 0.7533\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 558us/step - loss: 0.6060 - accuracy: 0.7600\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 602us/step - loss: 0.6047 - accuracy: 0.7600\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 609us/step - loss: 0.6035 - accuracy: 0.7600\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 557us/step - loss: 0.6023 - accuracy: 0.7600\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 526us/step - loss: 0.6010 - accuracy: 0.7600\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 630us/step - loss: 0.5997 - accuracy: 0.7600\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 627us/step - loss: 0.5985 - accuracy: 0.7600\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 615us/step - loss: 0.5973 - accuracy: 0.7600\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 753us/step - loss: 0.5961 - accuracy: 0.7600\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 731us/step - loss: 0.5949 - accuracy: 0.7600\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 624us/step - loss: 0.5936 - accuracy: 0.7600\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 637us/step - loss: 0.5924 - accuracy: 0.7600\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 629us/step - loss: 0.5912 - accuracy: 0.7600\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.5901 - accuracy: 0.7600\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 828us/step - loss: 0.5889 - accuracy: 0.7600\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 700us/step - loss: 0.5878 - accuracy: 0.7600\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 571us/step - loss: 0.5866 - accuracy: 0.7600\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 614us/step - loss: 0.5854 - accuracy: 0.7600\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 622us/step - loss: 0.5843 - accuracy: 0.7600\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 670us/step - loss: 0.5831 - accuracy: 0.7600\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.5820 - accuracy: 0.7600\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 602us/step - loss: 0.5808 - accuracy: 0.7600\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.5585 - accuracy: 0.84 - 0s 551us/step - loss: 0.5797 - accuracy: 0.7600\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 706us/step - loss: 0.5786 - accuracy: 0.7600\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 584us/step - loss: 0.5774 - accuracy: 0.7600\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 731us/step - loss: 0.5764 - accuracy: 0.7600\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 637us/step - loss: 0.5753 - accuracy: 0.7600\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 545us/step - loss: 0.5742 - accuracy: 0.7600\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 540us/step - loss: 0.5731 - accuracy: 0.7733\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 638us/step - loss: 0.5720 - accuracy: 0.7800\n",
      "Epoch 244/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 749us/step - loss: 0.5709 - accuracy: 0.7800\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.5700 - accuracy: 0.7800\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 720us/step - loss: 0.5689 - accuracy: 0.7800\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 659us/step - loss: 0.5678 - accuracy: 0.7867\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 603us/step - loss: 0.5668 - accuracy: 0.7800\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 705us/step - loss: 0.5658 - accuracy: 0.7867\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 656us/step - loss: 0.5647 - accuracy: 0.7867\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5637 - accuracy: 0.7867\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 735us/step - loss: 0.5626 - accuracy: 0.7867\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 636us/step - loss: 0.5616 - accuracy: 0.7867\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 658us/step - loss: 0.5606 - accuracy: 0.7867\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 665us/step - loss: 0.5596 - accuracy: 0.7867\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 557us/step - loss: 0.5586 - accuracy: 0.7867\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 551us/step - loss: 0.5576 - accuracy: 0.7867\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.5566 - accuracy: 0.7867\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 556us/step - loss: 0.5558 - accuracy: 0.7867\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 627us/step - loss: 0.5546 - accuracy: 0.8000\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 686us/step - loss: 0.5537 - accuracy: 0.8000\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 589us/step - loss: 0.5527 - accuracy: 0.8000\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 560us/step - loss: 0.5518 - accuracy: 0.8000\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 666us/step - loss: 0.5508 - accuracy: 0.8000\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 747us/step - loss: 0.5499 - accuracy: 0.8000\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 544us/step - loss: 0.5490 - accuracy: 0.8000\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 592us/step - loss: 0.5480 - accuracy: 0.8000\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 563us/step - loss: 0.5471 - accuracy: 0.8000\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 605us/step - loss: 0.5461 - accuracy: 0.8000\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 515us/step - loss: 0.5452 - accuracy: 0.8000\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 582us/step - loss: 0.5443 - accuracy: 0.8067\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.5434 - accuracy: 0.8067\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 523us/step - loss: 0.5425 - accuracy: 0.8067\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 535us/step - loss: 0.5416 - accuracy: 0.8067\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 615us/step - loss: 0.5407 - accuracy: 0.8067\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 526us/step - loss: 0.5398 - accuracy: 0.8067\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 618us/step - loss: 0.5389 - accuracy: 0.8067\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 522us/step - loss: 0.5380 - accuracy: 0.8067\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 757us/step - loss: 0.5371 - accuracy: 0.8067\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 682us/step - loss: 0.5363 - accuracy: 0.8067\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 706us/step - loss: 0.5355 - accuracy: 0.8067\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 643us/step - loss: 0.5345 - accuracy: 0.8067\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 637us/step - loss: 0.5337 - accuracy: 0.8067\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 580us/step - loss: 0.5328 - accuracy: 0.8067\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 556us/step - loss: 0.5320 - accuracy: 0.8067\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 532us/step - loss: 0.5311 - accuracy: 0.8067\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 659us/step - loss: 0.5303 - accuracy: 0.8067\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 582us/step - loss: 0.5294 - accuracy: 0.8067\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 507us/step - loss: 0.5286 - accuracy: 0.8133\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 619us/step - loss: 0.5278 - accuracy: 0.8200\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 483us/step - loss: 0.5270 - accuracy: 0.8200\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 555us/step - loss: 0.5261 - accuracy: 0.8200\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 478us/step - loss: 0.5253 - accuracy: 0.8200\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 548us/step - loss: 0.5245 - accuracy: 0.8200\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 590us/step - loss: 0.5237 - accuracy: 0.8200\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 619us/step - loss: 0.5229 - accuracy: 0.8200\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 510us/step - loss: 0.5221 - accuracy: 0.8200\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 479us/step - loss: 0.5213 - accuracy: 0.8200\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 635us/step - loss: 0.5205 - accuracy: 0.8200\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 543us/step - loss: 0.5197 - accuracy: 0.8200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f74a436d2e0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X, y, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que ahora hemos obtenido una precisión del 97%, es mayor que la obtuvimos antes.\n",
    "# Pero la que obtuvimos antes es la válida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora tenemos que guardar el modelo\n",
    "model.save(\"final_iris_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora tenemos que guardar el Scaler\n",
    "import joblib\n",
    "joblib.dump(scaler, \"iris_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción sobre una simple flor\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el modelo\n",
    "flower_model = load_model(\"final_iris_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el scaler\n",
    "flower_scaler = joblib.load(\"iris_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hagamos una predicción. Vamos a crear una función que:\n",
    "# 1.- Reciba un modelo como parámetro\n",
    "# 2.- Reciba un scaler como parémtro\n",
    "# 3.- Reciba unos datos como entrada para clasificar\n",
    "\n",
    "# Lo común es utilizar el formato json tanto para enviar datos como para obtener la predicción\n",
    "# Formato para envío de datos a la función de evaluación\n",
    "flower_example = {\n",
    "    \"sepal_length\": 5.1,\n",
    "    \"sepal_width\": 3.5,\n",
    "    \"petal_length\": 1.4,\n",
    "    \"petal_width\": 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función\n",
    "\n",
    "def return_prediction(model, scaler, sample_json):\n",
    "    \n",
    "    s_len = sample_json[\"sepal_length\"]\n",
    "    s_wid = sample_json[\"sepal_width\"]\n",
    "    p_len = sample_json[\"petal_length\"]\n",
    "    p_wid = sample_json[\"petal_width\"]\n",
    "    \n",
    "    # Composición de las medidas de una simple flor\n",
    "    flower = [[s_len, s_wid, p_len, p_wid]]\n",
    "    \n",
    "    # Como ya hemos cargado el Scaler, lo aplicamos\n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    # Realizamos la predicción\n",
    "    # Pero antes recordemos el 'encoder' que definimos antes\n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    # encoder.classes_ = setosa, versicolor, virginica\n",
    "    # Con esto obtendremos 0, 1 ó 2. Pero en un array\n",
    "    # class_ind = model.predict_classes(flower)\n",
    "    # Para obtener el valor tomo el primer elemento\n",
    "    class_ind = model.predict_classes(flower)[0]\n",
    "    \n",
    "    return classes[class_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hagamos la invocación\n",
    "return_prediction(flower_model, flower_scaler, flower_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR DEPLOYMENT\n",
    "\n",
    "Este será todo el código que necesitemos ejecutar en la aplicación Flask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "flower_model = load_model(\"final_iris_model.h5\")\n",
    "flower_scaler = joblib.load(\"iris_scaler.pkl\")\n",
    "\n",
    "def return_prediction(model, scaler, sample_json):\n",
    "    s_len = sample_json[\"sepal_length\"]\n",
    "    s_wid = sample_json[\"sepal_width\"]\n",
    "    p_len = sample_json[\"petal_length\"]\n",
    "    p_wid = sample_json[\"petal_width\"]\n",
    "    flower = [[s_len, s_wid, p_len, p_wid]]\n",
    "    flower = scaler.transform(flower)\n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    class_ind = model.predict_classes(flower)[0]\n",
    "    return classes[class_ind]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
